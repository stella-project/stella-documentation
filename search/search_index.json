{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to STELLA's documentation! Introduction Participants Tutorial: Ranking micro-service Tutorial: Recommendation micro-service for datasets Tutorial: Recommendation micro-service for publications Resources Sites & Organizers Setup guide Multi-container application based on Pyterrier API Reference Micro-service Multi-container application Central server Developer Information Environment variables Multi-container application Central server","title":"Home"},{"location":"#welcome-to-stellas-documentation","text":"","title":"Welcome to STELLA's documentation!"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#participants","text":"Tutorial: Ranking micro-service Tutorial: Recommendation micro-service for datasets Tutorial: Recommendation micro-service for publications Resources","title":"Participants"},{"location":"#sites-organizers","text":"Setup guide Multi-container application based on Pyterrier","title":"Sites &amp; Organizers"},{"location":"#api-reference","text":"Micro-service Multi-container application Central server","title":"API Reference"},{"location":"#developer-information","text":"","title":"Developer Information"},{"location":"#environment-variables","text":"Multi-container application Central server","title":"Environment variables"},{"location":"about/","text":"STELLA (Infra ST rucutr E s for L iving LA bs) offers an Evaluation-as-a-Service platform for living lab experiments with ranking and recommender systems. By using STELLA, researchers can evaluate their experimental systems based on user feedback which stands in contrast to (or complements) the Cranfield-style approaches with test collections in offline evaluations. STELLA facilitates conventional AB tests but also more data-efficient interleaving experiments in which results lists of two ranking or recommender functions are mixed. A fundamental component of STELLA is the integration of experimental systems as micro-services. While previous living labs restricted the system results to the most popular top-k queries, we allow more comprehensive evaluations by integrating micro-services with entire retrieval and recommender systems. The Living Labs for Academic Search (LiLAS) lab at CLEF made use of the STELLA infrastructure and served as the first test-bed to evaluate the feasibility of our new infrastructure design. We welcome contributions and look for collaborations with researchers and sites alike.","title":"About"},{"location":"api-reference/mca/","text":"Ranking REST endpoint: GET /stella/api/v1/ranking?query=<string:query>&page=<int:page>&rpp=<int:rpp>&sid=<int:sid>&container=<string:container> Explanation: query : the query string page : the number of the start page (optional) rpp : the number of results per page (optional) container : name of the container that contains either the baseline or one of the experimental systems (optional) sid : the session identifier (optional) Output (interleaved ranking): {'body': {'1': {'docid': 'M27622217', 'type': 'BASE'}, '2': {'docid': 'M27251231', 'type': 'EXP'}, '3': {'docid': 'M27692969', 'type': 'BASE'}, '4': {'docid': 'M26350569', 'type': 'EXP'}, '5': {'docid': 'M26715777', 'type': 'EXP'}, '6': {'docid': 'M26650940', 'type': 'BASE'}, '7': {'docid': 'M27098271', 'type': 'EXP'}, '8': {'docid': 'M28381438', 'type': 'BASE'}, '9': {'docid': 'M27763523', 'type': 'EXP'}, '10': {'docid': 'M27157745', 'type': 'BASE'}, '11': {'docid': 'M28066266', 'type': 'EXP'}, '12': {'docid': 'M26874427', 'type': 'BASE'}, '13': {'docid': 'M27133457', 'type': 'EXP'}, '14': {'docid': 'M26791355', 'type': 'BASE'}, '15': {'docid': 'M27157753', 'type': 'BASE'}, '16': {'docid': 'M27167258', 'type': 'EXP'}, '17': {'docid': 'M27524068', 'type': 'EXP'}, '18': {'docid': 'M26824628', 'type': 'BASE'}, '19': {'docid': 'M26967532', 'type': 'EXP'}}, 'header': {'container': {'base': 'rank_elastic_base', 'exp': 'rank_elastic'}, 'page': 0, 'q': 'vaccine', 'rid': 3, 'rpp': 20, 'hits': 12312, 'sid': 1}} Explanation: header : header containing meta information about the returned result body : body with rank positions, identifiers, and type of the corresponding system docid : the document identifier type : type of system can be either BASE or EXP container : dictionary with names of the experimental system and optional baseline system page : the number of the start page q : the query string rid : the ranking identifier rpp : the number of results per page hits : the number of total hits sid : the session identifier Output (non-interleaved ranking): {'body': {'1': {'docid': 'M27622217', 'type': 'EXP'}, '2': {'docid': 'M27251231', 'type': 'EXP'}, '3': {'docid': 'M27692969', 'type': 'EXP'}, '4': {'docid': 'M26350569', 'type': 'EXP'}, '5': {'docid': 'M26715777', 'type': 'EXP'}, '6': {'docid': 'M26650940', 'type': 'EXP'}, '7': {'docid': 'M27098271', 'type': 'EXP'}, '8': {'docid': 'M28381438', 'type': 'EXP'}, '9': {'docid': 'M27763523', 'type': 'EXP'}, '10': {'docid': 'M27157745', 'type': 'EXP'}, '11': {'docid': 'M28066266', 'type': 'EXP'}, '12': {'docid': 'M26874427', 'type': 'EXP'}, '13': {'docid': 'M27133457', 'type': 'EXP'}, '14': {'docid': 'M26791355', 'type': 'EXP'}, '15': {'docid': 'M27157753', 'type': 'EXP'}, '16': {'docid': 'M27167258', 'type': 'EXP'}, '17': {'docid': 'M27524068', 'type': 'EXP'}, '18': {'docid': 'M26824628', 'type': 'EXP'}, '19': {'docid': 'M26967532', 'type': 'EXP'}}, 'header': {'container': {'exp': 'rank_elastic'}, 'page': 0, 'q': 'vaccine', 'rid': 1, 'rpp': 20, 'hits': 12312, 'sid': 1}} Explanation: See above. Feedback REST endpoint: POST /stella/api/v1/ranking/rid=<int:rid>/feedback Explanation: sid : the session identifier rid : the ranking identifier Payload: {'clicks': {'1': {'clicked': False, 'date': None, 'docid': 'M26923455', 'type': 'EXP'}, '2': {'clicked': False, 'date': None, 'docid': 'M25600519', 'type': 'EXP'}, '3': {'clicked': True, 'date': '2020-07-29 16:06:51', 'docid': 'M27515393', 'type': 'EXP'}, '4': {'clicked': False, 'date': None, 'docid': 'M27572122', 'type': 'EXP'}, '5': {'clicked': False, 'date': None, 'docid': 'M27357208', 'type': 'EXP'}, '6': {'clicked': True, 'date': '2020-07-29 16:06:51', 'docid': 'M27309042', 'type': 'EXP'}, '7': {'clicked': False, 'date': None, 'docid': 'M27237391', 'type': 'EXP'}, '8': {'clicked': False, 'date': None, 'docid': 'M27279275', 'type': 'EXP'}, '9': {'clicked': False, 'date': None, 'docid': 'M26813237', 'type': 'EXP'} '10': {'clicked': False, 'date': None, 'docid': 'M27049797', 'type': 'EXP'}, '11': {'clicked': False, 'date': None, 'docid': 'M27531820', 'type': 'EXP'}, '12': {'clicked': False, 'date': None, 'docid': 'M27338346', 'type': 'EXP'}, '13': {'clicked': False, 'date': None, 'docid': 'M27999240', 'type': 'EXP'}, '14': {'clicked': False, 'date': None, 'docid': 'M26613600', 'type': 'EXP'}, '15': {'clicked': False, 'date': None, 'docid': 'M27356552', 'type': 'EXP'}, '16': {'clicked': False, 'date': None, 'docid': 'M27783754', 'type': 'EXP'}, '17': {'clicked': False, 'date': None, 'docid': 'M27278100', 'type': 'EXP'}, '18': {'clicked': False, 'date': None, 'docid': 'M27531823', 'type': 'EXP'}, '19': {'clicked': False, 'date': None, 'docid': 'M26860287', 'type': 'EXP'}}, 'end': '2020-07-29 16:12:53', 'interleave': True, 'start': '2020-07-29 16:06:51'} Explanation: start : time of session start, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' interleave : boolean value indicating if the result list has been interleaved end : time of session end, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' clicks : dicitionary containing document identifiers and their corresponding clicks clicked : boolean values indicating whether document has been clicked or not date : time when click happend, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' docid : the document identifier system : string value indicating if the corresponding system is baseline ( BASE ) or experimental ( EXP ) Recommendations REST endpoint: Datasets GET /stella/api/v1/recommendation/datasets?itemid=<string:itemid>&page=<int:page>&rpp=<int:rpp>&sid=<int:sid>&container=<string:container> Explanation: itemid : the target item of the recommendations page : the number of the start page (optional) rpp : the number of results per page (optional) sid : the session identifier (optional) container : name of the container that contains either the baseline or one of the experimental systems (optional) Publications GET /stella/api/v1/recommendation/publications?itemid=<string:itemid>&page=<int:page>&rpp=<int:rpp>&sid=<int:sid>&container=<string:container> Explanation: See above. Output (interleaved recommendation): {'body': {'1': {'docid': 'M27388739', 'type': 'BASE'}, '2': {'docid': 'M27338344', 'type': 'EXP'}, '3': {'docid': 'M26207529', 'type': 'EXP'}, '4': {'docid': 'M27216378', 'type': 'BASE'}, '5': {'docid': 'M26938486', 'type': 'BASE'}, '6': {'docid': 'M26612070', 'type': 'EXP'}, '7': {'docid': 'M27641359', 'type': 'BASE'}, '8': {'docid': 'M27567522', 'type': 'EXP'}, '9': {'docid': 'M27897418', 'type': 'BASE'}}, 'header': {'container': {'base': 'recom_tfidf_base', 'exp': 'recom_tfidf'}, 'itemid': 'M26923455', 'page': 0, 'rid': 4, 'rpp': 10, 'hits': 24, 'sid': 2, 'type': 'PUB'}} Explanation: header : header containing meta information about the returned result body : body with positions, identifiers, and type of the corresponding system docid : the document identifier type : type of system can be either BASE or EXP container : dictionary with names of the experimental system and optional baseline system itemid : the target item of the recommendations page : the number of the start page rid : the recommendation identifier rpp : the number of results per page hits : the number of total hits sid : the session identifier type : type of system can be either BASE or EXP Output (non-interleaved recommendation): {'body': {'1': {'docid': 'M27038470', 'type': 'EXP'}, '2': {'docid': 'M27342969', 'type': 'EXP'}, '3': {'docid': 'M26774951', 'type': 'EXP'}, '4': {'docid': 'M27912945', 'type': 'EXP'}, '5': {'docid': 'M26797943', 'type': 'EXP'}, '6': {'docid': 'M25359468', 'type': 'EXP'}, '7': {'docid': 'M26969740', 'type': 'EXP'}, '8': {'docid': 'M27613427', 'type': 'EXP'}, '9': {'docid': 'M27976545', 'type': 'EXP'}}, 'header': {'container': {'exp': 'recom_tfidf'}, 'itemid': 'M26923455', 'page': 0, 'rid': 2, 'rpp': 10, 'hits': 11, 'sid': 2, 'type': 'PUB'}} Explanation: See above. Feedback REST endpoint: POST /stella/api/v1/recommendation/rid=rid=<int:rid>/feedback Explanation: rid : the recommendation identifier {'clicks': {'1': {'clicked': False, 'date': None, 'docid': 'M27160449', 'type': 'EXP'}, '2': {'clicked': False, 'date': None, 'docid': 'M27888935', 'type': 'BASE'}, '3': {'clicked': False, 'date': None, 'docid': 'M27088628', 'type': 'EXP'}, '4': {'clicked': False, 'date': None, 'docid': 'M27064543', 'type': 'BASE'}, '5': {'clicked': False, 'date': None, 'docid': 'M27717979', 'type': 'EXP'}, '6': {'clicked': True, 'date': '2020-07-29 17:11:18', 'docid': 'M27077760', 'type': 'BASE'}, '7': {'clicked': False, 'date': None, 'docid': 'M27638054', 'type': 'BASE'}, '8': {'clicked': False, 'date': None, 'docid': 'M26360828', 'type': 'EXP'}, '9': {'clicked': False, 'date': None, 'docid': 'M27554937', 'type': 'BASE'}}, 'end': '2020-07-29 17:59:24', 'interleave': True, 'start': '2020-07-29 17:11:18'} Explanation: start : time of session start, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' interleave : boolean value indicating if the result list has been interleaved end : time of session end, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' clicks : dicitionary containing document identifiers and their corresponding clicks clicked : boolean values indicating whether document has been clicked or not date : time when click happend, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' docid : the document identifier system : string value indicating if the corresponding system is baseline ( BASE ) or experimental ( EXP ) Indexing GET /stella/api/v1/index/bulk Explanation: Start indexing all containers in parallel. GET /stella/api/v1/index/<string:container_name> Explanation: container_name : Name of the specific container to be indexed. Exit sessions GET /stella/api/v1/sessions/<int:sid>/exit Explanation: sid : Identifier of the session to be exited.","title":"Multi-container application"},{"location":"api-reference/mca/#ranking","text":"","title":"Ranking"},{"location":"api-reference/mca/#rest-endpoint","text":"GET /stella/api/v1/ranking?query=<string:query>&page=<int:page>&rpp=<int:rpp>&sid=<int:sid>&container=<string:container>","title":"REST endpoint:"},{"location":"api-reference/mca/#explanation","text":"query : the query string page : the number of the start page (optional) rpp : the number of results per page (optional) container : name of the container that contains either the baseline or one of the experimental systems (optional) sid : the session identifier (optional)","title":"Explanation:"},{"location":"api-reference/mca/#output-interleaved-ranking","text":"{'body': {'1': {'docid': 'M27622217', 'type': 'BASE'}, '2': {'docid': 'M27251231', 'type': 'EXP'}, '3': {'docid': 'M27692969', 'type': 'BASE'}, '4': {'docid': 'M26350569', 'type': 'EXP'}, '5': {'docid': 'M26715777', 'type': 'EXP'}, '6': {'docid': 'M26650940', 'type': 'BASE'}, '7': {'docid': 'M27098271', 'type': 'EXP'}, '8': {'docid': 'M28381438', 'type': 'BASE'}, '9': {'docid': 'M27763523', 'type': 'EXP'}, '10': {'docid': 'M27157745', 'type': 'BASE'}, '11': {'docid': 'M28066266', 'type': 'EXP'}, '12': {'docid': 'M26874427', 'type': 'BASE'}, '13': {'docid': 'M27133457', 'type': 'EXP'}, '14': {'docid': 'M26791355', 'type': 'BASE'}, '15': {'docid': 'M27157753', 'type': 'BASE'}, '16': {'docid': 'M27167258', 'type': 'EXP'}, '17': {'docid': 'M27524068', 'type': 'EXP'}, '18': {'docid': 'M26824628', 'type': 'BASE'}, '19': {'docid': 'M26967532', 'type': 'EXP'}}, 'header': {'container': {'base': 'rank_elastic_base', 'exp': 'rank_elastic'}, 'page': 0, 'q': 'vaccine', 'rid': 3, 'rpp': 20, 'hits': 12312, 'sid': 1}}","title":"Output (interleaved ranking):"},{"location":"api-reference/mca/#explanation_1","text":"header : header containing meta information about the returned result body : body with rank positions, identifiers, and type of the corresponding system docid : the document identifier type : type of system can be either BASE or EXP container : dictionary with names of the experimental system and optional baseline system page : the number of the start page q : the query string rid : the ranking identifier rpp : the number of results per page hits : the number of total hits sid : the session identifier","title":"Explanation:"},{"location":"api-reference/mca/#output-non-interleaved-ranking","text":"{'body': {'1': {'docid': 'M27622217', 'type': 'EXP'}, '2': {'docid': 'M27251231', 'type': 'EXP'}, '3': {'docid': 'M27692969', 'type': 'EXP'}, '4': {'docid': 'M26350569', 'type': 'EXP'}, '5': {'docid': 'M26715777', 'type': 'EXP'}, '6': {'docid': 'M26650940', 'type': 'EXP'}, '7': {'docid': 'M27098271', 'type': 'EXP'}, '8': {'docid': 'M28381438', 'type': 'EXP'}, '9': {'docid': 'M27763523', 'type': 'EXP'}, '10': {'docid': 'M27157745', 'type': 'EXP'}, '11': {'docid': 'M28066266', 'type': 'EXP'}, '12': {'docid': 'M26874427', 'type': 'EXP'}, '13': {'docid': 'M27133457', 'type': 'EXP'}, '14': {'docid': 'M26791355', 'type': 'EXP'}, '15': {'docid': 'M27157753', 'type': 'EXP'}, '16': {'docid': 'M27167258', 'type': 'EXP'}, '17': {'docid': 'M27524068', 'type': 'EXP'}, '18': {'docid': 'M26824628', 'type': 'EXP'}, '19': {'docid': 'M26967532', 'type': 'EXP'}}, 'header': {'container': {'exp': 'rank_elastic'}, 'page': 0, 'q': 'vaccine', 'rid': 1, 'rpp': 20, 'hits': 12312, 'sid': 1}}","title":"Output (non-interleaved ranking):"},{"location":"api-reference/mca/#explanation_2","text":"See above.","title":"Explanation:"},{"location":"api-reference/mca/#feedback","text":"","title":"Feedback"},{"location":"api-reference/mca/#rest-endpoint_1","text":"POST /stella/api/v1/ranking/rid=<int:rid>/feedback","title":"REST endpoint:"},{"location":"api-reference/mca/#explanation_3","text":"sid : the session identifier rid : the ranking identifier","title":"Explanation:"},{"location":"api-reference/mca/#payload","text":"{'clicks': {'1': {'clicked': False, 'date': None, 'docid': 'M26923455', 'type': 'EXP'}, '2': {'clicked': False, 'date': None, 'docid': 'M25600519', 'type': 'EXP'}, '3': {'clicked': True, 'date': '2020-07-29 16:06:51', 'docid': 'M27515393', 'type': 'EXP'}, '4': {'clicked': False, 'date': None, 'docid': 'M27572122', 'type': 'EXP'}, '5': {'clicked': False, 'date': None, 'docid': 'M27357208', 'type': 'EXP'}, '6': {'clicked': True, 'date': '2020-07-29 16:06:51', 'docid': 'M27309042', 'type': 'EXP'}, '7': {'clicked': False, 'date': None, 'docid': 'M27237391', 'type': 'EXP'}, '8': {'clicked': False, 'date': None, 'docid': 'M27279275', 'type': 'EXP'}, '9': {'clicked': False, 'date': None, 'docid': 'M26813237', 'type': 'EXP'} '10': {'clicked': False, 'date': None, 'docid': 'M27049797', 'type': 'EXP'}, '11': {'clicked': False, 'date': None, 'docid': 'M27531820', 'type': 'EXP'}, '12': {'clicked': False, 'date': None, 'docid': 'M27338346', 'type': 'EXP'}, '13': {'clicked': False, 'date': None, 'docid': 'M27999240', 'type': 'EXP'}, '14': {'clicked': False, 'date': None, 'docid': 'M26613600', 'type': 'EXP'}, '15': {'clicked': False, 'date': None, 'docid': 'M27356552', 'type': 'EXP'}, '16': {'clicked': False, 'date': None, 'docid': 'M27783754', 'type': 'EXP'}, '17': {'clicked': False, 'date': None, 'docid': 'M27278100', 'type': 'EXP'}, '18': {'clicked': False, 'date': None, 'docid': 'M27531823', 'type': 'EXP'}, '19': {'clicked': False, 'date': None, 'docid': 'M26860287', 'type': 'EXP'}}, 'end': '2020-07-29 16:12:53', 'interleave': True, 'start': '2020-07-29 16:06:51'}","title":"Payload:"},{"location":"api-reference/mca/#explanation_4","text":"start : time of session start, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' interleave : boolean value indicating if the result list has been interleaved end : time of session end, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' clicks : dicitionary containing document identifiers and their corresponding clicks clicked : boolean values indicating whether document has been clicked or not date : time when click happend, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' docid : the document identifier system : string value indicating if the corresponding system is baseline ( BASE ) or experimental ( EXP )","title":"Explanation:"},{"location":"api-reference/mca/#recommendations","text":"","title":"Recommendations"},{"location":"api-reference/mca/#rest-endpoint_2","text":"","title":"REST endpoint:"},{"location":"api-reference/mca/#datasets","text":"GET /stella/api/v1/recommendation/datasets?itemid=<string:itemid>&page=<int:page>&rpp=<int:rpp>&sid=<int:sid>&container=<string:container>","title":"Datasets"},{"location":"api-reference/mca/#explanation_5","text":"itemid : the target item of the recommendations page : the number of the start page (optional) rpp : the number of results per page (optional) sid : the session identifier (optional) container : name of the container that contains either the baseline or one of the experimental systems (optional)","title":"Explanation:"},{"location":"api-reference/mca/#publications","text":"GET /stella/api/v1/recommendation/publications?itemid=<string:itemid>&page=<int:page>&rpp=<int:rpp>&sid=<int:sid>&container=<string:container>","title":"Publications"},{"location":"api-reference/mca/#explanation_6","text":"See above.","title":"Explanation:"},{"location":"api-reference/mca/#output-interleaved-recommendation","text":"{'body': {'1': {'docid': 'M27388739', 'type': 'BASE'}, '2': {'docid': 'M27338344', 'type': 'EXP'}, '3': {'docid': 'M26207529', 'type': 'EXP'}, '4': {'docid': 'M27216378', 'type': 'BASE'}, '5': {'docid': 'M26938486', 'type': 'BASE'}, '6': {'docid': 'M26612070', 'type': 'EXP'}, '7': {'docid': 'M27641359', 'type': 'BASE'}, '8': {'docid': 'M27567522', 'type': 'EXP'}, '9': {'docid': 'M27897418', 'type': 'BASE'}}, 'header': {'container': {'base': 'recom_tfidf_base', 'exp': 'recom_tfidf'}, 'itemid': 'M26923455', 'page': 0, 'rid': 4, 'rpp': 10, 'hits': 24, 'sid': 2, 'type': 'PUB'}}","title":"Output (interleaved recommendation):"},{"location":"api-reference/mca/#explanation_7","text":"header : header containing meta information about the returned result body : body with positions, identifiers, and type of the corresponding system docid : the document identifier type : type of system can be either BASE or EXP container : dictionary with names of the experimental system and optional baseline system itemid : the target item of the recommendations page : the number of the start page rid : the recommendation identifier rpp : the number of results per page hits : the number of total hits sid : the session identifier type : type of system can be either BASE or EXP","title":"Explanation:"},{"location":"api-reference/mca/#output-non-interleaved-recommendation","text":"{'body': {'1': {'docid': 'M27038470', 'type': 'EXP'}, '2': {'docid': 'M27342969', 'type': 'EXP'}, '3': {'docid': 'M26774951', 'type': 'EXP'}, '4': {'docid': 'M27912945', 'type': 'EXP'}, '5': {'docid': 'M26797943', 'type': 'EXP'}, '6': {'docid': 'M25359468', 'type': 'EXP'}, '7': {'docid': 'M26969740', 'type': 'EXP'}, '8': {'docid': 'M27613427', 'type': 'EXP'}, '9': {'docid': 'M27976545', 'type': 'EXP'}}, 'header': {'container': {'exp': 'recom_tfidf'}, 'itemid': 'M26923455', 'page': 0, 'rid': 2, 'rpp': 10, 'hits': 11, 'sid': 2, 'type': 'PUB'}}","title":"Output (non-interleaved recommendation):"},{"location":"api-reference/mca/#explanation_8","text":"See above.","title":"Explanation:"},{"location":"api-reference/mca/#feedback_1","text":"","title":"Feedback"},{"location":"api-reference/mca/#rest-endpoint_3","text":"POST /stella/api/v1/recommendation/rid=rid=<int:rid>/feedback","title":"REST endpoint:"},{"location":"api-reference/mca/#explanation_9","text":"rid : the recommendation identifier {'clicks': {'1': {'clicked': False, 'date': None, 'docid': 'M27160449', 'type': 'EXP'}, '2': {'clicked': False, 'date': None, 'docid': 'M27888935', 'type': 'BASE'}, '3': {'clicked': False, 'date': None, 'docid': 'M27088628', 'type': 'EXP'}, '4': {'clicked': False, 'date': None, 'docid': 'M27064543', 'type': 'BASE'}, '5': {'clicked': False, 'date': None, 'docid': 'M27717979', 'type': 'EXP'}, '6': {'clicked': True, 'date': '2020-07-29 17:11:18', 'docid': 'M27077760', 'type': 'BASE'}, '7': {'clicked': False, 'date': None, 'docid': 'M27638054', 'type': 'BASE'}, '8': {'clicked': False, 'date': None, 'docid': 'M26360828', 'type': 'EXP'}, '9': {'clicked': False, 'date': None, 'docid': 'M27554937', 'type': 'BASE'}}, 'end': '2020-07-29 17:59:24', 'interleave': True, 'start': '2020-07-29 17:11:18'}","title":"Explanation:"},{"location":"api-reference/mca/#explanation_10","text":"start : time of session start, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' interleave : boolean value indicating if the result list has been interleaved end : time of session end, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' clicks : dicitionary containing document identifiers and their corresponding clicks clicked : boolean values indicating whether document has been clicked or not date : time when click happend, has to be provided as datetime-formatted string like 'YYYY-MM-DD HH:MM:SS' docid : the document identifier system : string value indicating if the corresponding system is baseline ( BASE ) or experimental ( EXP )","title":"Explanation:"},{"location":"api-reference/mca/#indexing","text":"GET /stella/api/v1/index/bulk","title":"Indexing"},{"location":"api-reference/mca/#explanation_11","text":"Start indexing all containers in parallel. GET /stella/api/v1/index/<string:container_name>","title":"Explanation:"},{"location":"api-reference/mca/#explanation_12","text":"container_name : Name of the specific container to be indexed.","title":"Explanation:"},{"location":"api-reference/mca/#exit-sessions","text":"GET /stella/api/v1/sessions/<int:sid>/exit","title":"Exit sessions"},{"location":"api-reference/mca/#explanation_13","text":"sid : Identifier of the session to be exited.","title":"Explanation:"},{"location":"api-reference/micro-service/","text":"Ranking REST endpoint: GET container_name/ranking?query=<string:qstr>&page=<int:pnum>&rpp=<int:rppnum> Explanation: container_name : name of the container that contains either the baseline or one of the experimental systems query : the query string page : the number of the start page rpp : the number of results per page Output: {'itemlist': ['M26721328', 'M26923455', 'M25600519', 'M27515393', 'M27572122', 'M27357208', 'M27309042', 'M27237391', 'M27279275', 'M26813237', 'M27049797', 'M27531820', 'M27338346', 'M27999240', 'M26613600', 'M27356552', 'M27783754', 'M27278100', 'M27531823', 'M26860287'], 'num_found': 20, 'page': 0, 'query': 'vaccine', 'rpp': 20} Explanation: itemlist : a list containing the document identifiers num_found : the total number of documents found for the given query page : the number of the start page query : the query string rpp : the number of results per page Recommendation REST endpoint: GET container_name/recommendation/datasets?itemid=<string:itemidstr>&page=<int:pnum>&rpp=<int:rppnum> GET container_name/recommendation/publications?itemid=<string:itemidstr>&page=<int:pnum>&rpp=<int:rppnum> Explanation: container_name : name of the container that contains either the baseline or one of the experimental systems datasets/publications : specify if datasets of publications should be recommended itemid : the target item of the recommendations page : the number of the start page rpp : the number of results per page Output: {'itemid': 'M26923455', 'itemlist': ['M27852061', 'M26673108', 'M27894536', 'M27293030', 'M27133708', 'M26841192', 'M27144310', 'M27353833', 'M27287107', 'M27658597'], 'num_found': 10, 'page': 0, 'rpp': 10} Explanation: itemid : the target item of the recommendations itemlist : a list containing the document identifiers num_found : the total number of documents found for the given query page : the number of the start page rpp : the number of results per page","title":"Micro-service"},{"location":"api-reference/micro-service/#ranking","text":"","title":"Ranking"},{"location":"api-reference/micro-service/#rest-endpoint","text":"GET container_name/ranking?query=<string:qstr>&page=<int:pnum>&rpp=<int:rppnum>","title":"REST endpoint:"},{"location":"api-reference/micro-service/#explanation","text":"container_name : name of the container that contains either the baseline or one of the experimental systems query : the query string page : the number of the start page rpp : the number of results per page","title":"Explanation:"},{"location":"api-reference/micro-service/#output","text":"{'itemlist': ['M26721328', 'M26923455', 'M25600519', 'M27515393', 'M27572122', 'M27357208', 'M27309042', 'M27237391', 'M27279275', 'M26813237', 'M27049797', 'M27531820', 'M27338346', 'M27999240', 'M26613600', 'M27356552', 'M27783754', 'M27278100', 'M27531823', 'M26860287'], 'num_found': 20, 'page': 0, 'query': 'vaccine', 'rpp': 20}","title":"Output:"},{"location":"api-reference/micro-service/#explanation_1","text":"itemlist : a list containing the document identifiers num_found : the total number of documents found for the given query page : the number of the start page query : the query string rpp : the number of results per page","title":"Explanation:"},{"location":"api-reference/micro-service/#recommendation","text":"","title":"Recommendation"},{"location":"api-reference/micro-service/#rest-endpoint_1","text":"GET container_name/recommendation/datasets?itemid=<string:itemidstr>&page=<int:pnum>&rpp=<int:rppnum> GET container_name/recommendation/publications?itemid=<string:itemidstr>&page=<int:pnum>&rpp=<int:rppnum>","title":"REST endpoint:"},{"location":"api-reference/micro-service/#explanation_2","text":"container_name : name of the container that contains either the baseline or one of the experimental systems datasets/publications : specify if datasets of publications should be recommended itemid : the target item of the recommendations page : the number of the start page rpp : the number of results per page","title":"Explanation:"},{"location":"api-reference/micro-service/#output_1","text":"{'itemid': 'M26923455', 'itemlist': ['M27852061', 'M26673108', 'M27894536', 'M27293030', 'M27133708', 'M26841192', 'M27144310', 'M27353833', 'M27287107', 'M27658597'], 'num_found': 10, 'page': 0, 'rpp': 10}","title":"Output:"},{"location":"api-reference/micro-service/#explanation_3","text":"itemid : the target item of the recommendations itemlist : a list containing the document identifiers num_found : the total number of documents found for the given query page : the number of the start page rpp : the number of results per page","title":"Explanation:"},{"location":"api-reference/server/","text":"Feedback GET details of all feedbacks (see also util/GET_feedbacks.py ): /feedbacks GET details of feedback with id (see also util/GET_feedback.py ): /feedbacks/<int:id> POST new feedback for session with id (see also util/POST_feedback.py ): /sessions/<int:id>/feedbacks The payload should be provided as follows: { \"start\": \"2019-11-04 00:06:23\", \"end\": \"2019-11-04 00:10:38\", \"interleave\": \"True\", \"clicks\": [ {\"1\": {\"doc_id\": \"doc1\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"2\": {\"doc_id\": \"doc11\", \"clicked\": \"True\", \"date\": \"2019-11-04 00:08:15\", \"system\": \"BASE\"}}, {\"3\": {\"doc_id\": \"doc2\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"4\": {\"doc_id\": \"doc12\", \"clicked\": \"True\", \"date\": \"2019-11-04 00:06:23\", \"system\": \"BASE\"}}, {\"5\": {\"doc_id\": \"doc3\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"6\": {\"doc_id\": \"doc13\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}}, {\"7\": {\"doc_id\": \"doc4\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"8\": {\"doc_id\": \"doc14\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}}, {\"9\": {\"doc_id\": \"doc5\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"10\": {\"doc_id\": \"doc15\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}} ] } PUT details for feedback with id (see also util/PUT_feedback.py ): /feedbacks/<int:id>' The payload should be provided as follows: { \"start\": \"2019-11-04 00:06:23\", \"end\": \"2019-11-04 00:10:38\", \"interleave\": \"True\", \"clicks\": [ {\"1\": {\"doc_id\": \"doc1\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"2\": {\"doc_id\": \"doc11\", \"clicked\": \"True\", \"date\": \"2019-11-04 00:08:15\", \"system\": \"BASE\"}}, {\"3\": {\"doc_id\": \"doc2\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"4\": {\"doc_id\": \"doc12\", \"clicked\": \"True\", \"date\": \"2019-11-04 00:06:23\", \"system\": \"BASE\"}}, {\"5\": {\"doc_id\": \"doc3\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"6\": {\"doc_id\": \"doc13\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}}, {\"7\": {\"doc_id\": \"doc4\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"8\": {\"doc_id\": \"doc14\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}}, {\"9\": {\"doc_id\": \"doc5\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"10\": {\"doc_id\": \"doc15\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}} ] } Participant GET all systems of participant with id (see also util/GET_systems_of_participant.py ): /participants/<int:id>/systems GET all sessions of participant with id (see also util/GET_sessions_of_participant.py ): /participants/<int:id>/sessions Ranking GET details of ranking with id (see also util/GET_ranking.py ): /rankings/<int:id> GET a list of all ranking id s (see also util/GET_rankings.py ): /rankings POST ranking for feedback with id (see also util/POST_rankings.py ): /feedbacks/<int:id>/rankings The payload should be provided as follows: { \"q\": \"this is the query text\", \"q_date\": \"2019-11-04 00:04:00\", \"q_time\": 325, \"num_found\": 100, \"page\": 1, \"rpp\": 10, \"items\": [ {\"1\": \"doc1\", \"2\": \"doc2\", \"3\": \"doc3\", \"4\": \"doc4\", \"5\": \"doc5\", \"6\": \"doc6\", \"7\": \"doc7\", \"8\": \"doc8\", \"9\": \"doc9\", \"10\": \"doc10\"} ] } PUT ranking with id (see also util/PUT_ranking.py ): /rankings/<int:id> The payload should be provided as follows: { \"q\": \"this is the query text\", \"q_date\": \"2019-11-04 00:04:00\", \"q_time\": 325, \"num_found\": 100, \"page\": 1, \"rpp\": 10, \"items\": [ {\"1\": \"doc1\", \"2\": \"doc2\", \"3\": \"doc3\", \"4\": \"doc4\", \"5\": \"doc5\", \"6\": \"doc6\", \"7\": \"doc7\", \"8\": \"doc8\", \"9\": \"doc9\", \"10\": \"doc10\"} ] } Recommendation GET details of recommendation with id (see also util/GET_ranking.py that works analogously): /recommendations/<int:id> GET a list of all recommendation id s (see also util/GET_rankings.py that works analogously): /recommendations POST recommendation for feedback with id (see also util/POST_rankings.py that works analogously): /feedbacks/<int:id>/recommendations The payload should be provided as follows: { \"q\": \"docid\", \"q_date\": \"2019-11-04 00:04:00\", \"q_time\": 325, \"num_found\": 100, \"page\": 1, \"rpp\": 10, \"items\": [ {\"1\": \"doc1\", \"2\": \"doc2\", \"3\": \"doc3\", \"4\": \"doc4\", \"5\": \"doc5\", \"6\": \"doc6\", \"7\": \"doc7\", \"8\": \"doc8\", \"9\": \"doc9\", \"10\": \"doc10\"} ] } PUT recommendation with id (see also util/PUT_ranking.py that works analogously): /recommendations/<int:id> The payload should be provided as follows: { \"q\": \"docid\", \"q_date\": \"2019-11-04 00:04:00\", \"q_time\": 325, \"num_found\": 100, \"page\": 1, \"rpp\": 10, \"items\": [ {\"1\": \"doc1\", \"2\": \"doc2\", \"3\": \"doc3\", \"4\": \"doc4\", \"5\": \"doc5\", \"6\": \"doc6\", \"7\": \"doc7\", \"8\": \"doc8\", \"9\": \"doc9\", \"10\": \"doc10\"} ] } Session GET session with id (see also util/GET_session.py ): /sessions/<int:id> GET feedback from session with id (see also util/GET_feedbacks_of_session.py ): /sessions/<int:id>/feedbacks GET systems used in session with id : /sessions/<int:id>/systems Site GET site details, e.g. id , with the help of the name (see also util/GET_systems_at_site.py ): /sites/<string:name> GET sessions at site with id (see also util/GET_session_at_site.py ): /sites/<int:id>/sessions GET systems deployed at site with id (see also util/GET_systems_at_site.py ): /sites/<int:id>/systems POST new session at site with id (see also util/POST_sessions.py ): /sites/<int:id>/sessions The payload should be provided as follows: { \"site_user\": \"123.123.123.123\", \"start\": \"2020-02-20 20:02:20\", \"end\": \"2020-02-20 20:02:20\", \"system_ranking\": \"rank_exp_a\", \"system_recommendation\": \"rec_exp_a\" }","title":"Central server"},{"location":"api-reference/server/#feedback","text":"GET details of all feedbacks (see also util/GET_feedbacks.py ): /feedbacks GET details of feedback with id (see also util/GET_feedback.py ): /feedbacks/<int:id> POST new feedback for session with id (see also util/POST_feedback.py ): /sessions/<int:id>/feedbacks The payload should be provided as follows: { \"start\": \"2019-11-04 00:06:23\", \"end\": \"2019-11-04 00:10:38\", \"interleave\": \"True\", \"clicks\": [ {\"1\": {\"doc_id\": \"doc1\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"2\": {\"doc_id\": \"doc11\", \"clicked\": \"True\", \"date\": \"2019-11-04 00:08:15\", \"system\": \"BASE\"}}, {\"3\": {\"doc_id\": \"doc2\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"4\": {\"doc_id\": \"doc12\", \"clicked\": \"True\", \"date\": \"2019-11-04 00:06:23\", \"system\": \"BASE\"}}, {\"5\": {\"doc_id\": \"doc3\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"6\": {\"doc_id\": \"doc13\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}}, {\"7\": {\"doc_id\": \"doc4\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"8\": {\"doc_id\": \"doc14\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}}, {\"9\": {\"doc_id\": \"doc5\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"10\": {\"doc_id\": \"doc15\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}} ] } PUT details for feedback with id (see also util/PUT_feedback.py ): /feedbacks/<int:id>' The payload should be provided as follows: { \"start\": \"2019-11-04 00:06:23\", \"end\": \"2019-11-04 00:10:38\", \"interleave\": \"True\", \"clicks\": [ {\"1\": {\"doc_id\": \"doc1\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"2\": {\"doc_id\": \"doc11\", \"clicked\": \"True\", \"date\": \"2019-11-04 00:08:15\", \"system\": \"BASE\"}}, {\"3\": {\"doc_id\": \"doc2\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"4\": {\"doc_id\": \"doc12\", \"clicked\": \"True\", \"date\": \"2019-11-04 00:06:23\", \"system\": \"BASE\"}}, {\"5\": {\"doc_id\": \"doc3\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"6\": {\"doc_id\": \"doc13\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}}, {\"7\": {\"doc_id\": \"doc4\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"8\": {\"doc_id\": \"doc14\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}}, {\"9\": {\"doc_id\": \"doc5\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"EXP\"}}, {\"10\": {\"doc_id\": \"doc15\", \"clicked\": \"False\", \"date\": \"None\", \"system\": \"BASE\"}} ] }","title":"Feedback"},{"location":"api-reference/server/#participant","text":"GET all systems of participant with id (see also util/GET_systems_of_participant.py ): /participants/<int:id>/systems GET all sessions of participant with id (see also util/GET_sessions_of_participant.py ): /participants/<int:id>/sessions","title":"Participant"},{"location":"api-reference/server/#ranking","text":"GET details of ranking with id (see also util/GET_ranking.py ): /rankings/<int:id> GET a list of all ranking id s (see also util/GET_rankings.py ): /rankings POST ranking for feedback with id (see also util/POST_rankings.py ): /feedbacks/<int:id>/rankings The payload should be provided as follows: { \"q\": \"this is the query text\", \"q_date\": \"2019-11-04 00:04:00\", \"q_time\": 325, \"num_found\": 100, \"page\": 1, \"rpp\": 10, \"items\": [ {\"1\": \"doc1\", \"2\": \"doc2\", \"3\": \"doc3\", \"4\": \"doc4\", \"5\": \"doc5\", \"6\": \"doc6\", \"7\": \"doc7\", \"8\": \"doc8\", \"9\": \"doc9\", \"10\": \"doc10\"} ] } PUT ranking with id (see also util/PUT_ranking.py ): /rankings/<int:id> The payload should be provided as follows: { \"q\": \"this is the query text\", \"q_date\": \"2019-11-04 00:04:00\", \"q_time\": 325, \"num_found\": 100, \"page\": 1, \"rpp\": 10, \"items\": [ {\"1\": \"doc1\", \"2\": \"doc2\", \"3\": \"doc3\", \"4\": \"doc4\", \"5\": \"doc5\", \"6\": \"doc6\", \"7\": \"doc7\", \"8\": \"doc8\", \"9\": \"doc9\", \"10\": \"doc10\"} ] }","title":"Ranking"},{"location":"api-reference/server/#recommendation","text":"GET details of recommendation with id (see also util/GET_ranking.py that works analogously): /recommendations/<int:id> GET a list of all recommendation id s (see also util/GET_rankings.py that works analogously): /recommendations POST recommendation for feedback with id (see also util/POST_rankings.py that works analogously): /feedbacks/<int:id>/recommendations The payload should be provided as follows: { \"q\": \"docid\", \"q_date\": \"2019-11-04 00:04:00\", \"q_time\": 325, \"num_found\": 100, \"page\": 1, \"rpp\": 10, \"items\": [ {\"1\": \"doc1\", \"2\": \"doc2\", \"3\": \"doc3\", \"4\": \"doc4\", \"5\": \"doc5\", \"6\": \"doc6\", \"7\": \"doc7\", \"8\": \"doc8\", \"9\": \"doc9\", \"10\": \"doc10\"} ] } PUT recommendation with id (see also util/PUT_ranking.py that works analogously): /recommendations/<int:id> The payload should be provided as follows: { \"q\": \"docid\", \"q_date\": \"2019-11-04 00:04:00\", \"q_time\": 325, \"num_found\": 100, \"page\": 1, \"rpp\": 10, \"items\": [ {\"1\": \"doc1\", \"2\": \"doc2\", \"3\": \"doc3\", \"4\": \"doc4\", \"5\": \"doc5\", \"6\": \"doc6\", \"7\": \"doc7\", \"8\": \"doc8\", \"9\": \"doc9\", \"10\": \"doc10\"} ] }","title":"Recommendation"},{"location":"api-reference/server/#session","text":"GET session with id (see also util/GET_session.py ): /sessions/<int:id> GET feedback from session with id (see also util/GET_feedbacks_of_session.py ): /sessions/<int:id>/feedbacks GET systems used in session with id : /sessions/<int:id>/systems","title":"Session"},{"location":"api-reference/server/#site","text":"GET site details, e.g. id , with the help of the name (see also util/GET_systems_at_site.py ): /sites/<string:name> GET sessions at site with id (see also util/GET_session_at_site.py ): /sites/<int:id>/sessions GET systems deployed at site with id (see also util/GET_systems_at_site.py ): /sites/<int:id>/systems POST new session at site with id (see also util/POST_sessions.py ): /sites/<int:id>/sessions The payload should be provided as follows: { \"site_user\": \"123.123.123.123\", \"start\": \"2020-02-20 20:02:20\", \"end\": \"2020-02-20 20:02:20\", \"system_ranking\": \"rank_exp_a\", \"system_recommendation\": \"rec_exp_a\" }","title":"Site"},{"location":"develop/env-mca/","text":"Environment variable Meaning RANKSYS_LIST RANKSYS_PRECOM_LIST RANKSYS_BASE STELLA_SERVER_ADDRESS STELLA_SERVER_USER STELLA_SERVER_PASS STELLA_SERVER_USERNAME INTERLEAVE You can choose to interleave the results with the baseline system via INTERLEAVE . Per default interleaving is activated ( INTERLEAVE=True ) BULK_INDEX If all systems should start the indexing when launching the app leave BULK_INDEX=True . If BULK_INDEX=False , you can visit <ip-of-stella-app>/ and index the systems individually or by calling the corresponding REST-endpoints. DELETE_SENT_SESSION If DELETE_SENT_SESSION=True , all sessions will removed after they have been sent to the stella-server . INTERVAL_DB_CHECK This environment variables controls the time interval for checking the database for finished sessions. Time is specified in seconds, i.e. INTERVAL_DB_CHECK=3 will check every 3 seconds if there are new sessions that can be sent to the stella-server . SESSION_EXPIRATION This environment variables controls the time interval after the state of a sessions will automatically be set to \"finished\". Time is specified in seconds, i.e. SESSION_EXPIRATION=6 will make a session expire after 6 seconds.","title":"Multi-container application"},{"location":"develop/env-server/","text":"Environment variable Meaning FLASK_CONFIG POSTGRES_USER POSTGRES_PW POSTGRES_DB SECRET_KEY AUTOMATOR_GH_KEY ADMIN_MAIL ADMIN_PASS GESIS_MAIL GESIS_PASS LIVIVO_MAIL LIVIVO_PASS PARTA_MAIL PARTA_PASS PARTB_MAIL PARTB_PASS POSTGRES_USER POSTGRES_PASSWORD POSTGRES_DB","title":"Central server"},{"location":"guides/participants-ranking/","text":"How to integrate a ranking micro-service 1. Introduction The STELLA-framework enables participants to run and evaluate ranking and recommendation-systems in a Living-Lab scenario. The heart of STELLA-framework is the STELLA application, which is implemented as a a multi-container-application (MCA) by the sites (the search-engines) and handles communication between the site and participant-containers. This means every participant-system must be deployed as a docker image, which runs as a container inside STELLA application. In principle you have full freedom in choice of programming language and software tools. Your container only has to satisfy the constraints of a predefined REST-API. If you want to learn more about STELLA, please see our blog posts . This tutorial will guide you step-by-step through the process of integrating a ranking microservice into STELLA-infrastructure. You will learn how to build your own dockerized ranking-system with python. For this purpose we will use a document subset from the LIVIVO search engine. To give you a head start, we prepared a code template. That means, you just have to write a few lines of code to get your ranking-system running. 2. Prerequisites Before starting this tutorial, make sure all requirements in the README.md are fulfilled. 3. LIVIVO Dataset LIVIVO is an interdisciplinary search engine for literature and information in the field of life sciences. It is run by ZB MED \u2013 Information Centre for Life Sciences. LIVIVO draws on relevant scientific information from the ZB MED subject areas of medicine, health, nutrition, and environmental and agricultural sciences. (https://www.livivo.de/app/misc/help/about) In this tutorial we will work with a small subset of LIVIVO (30000 documents). See the following table for an explanation of fields. field description DBRECORDID primary document key TITLE document title ABSTRACT document abstract AUTHOR list of authors INSTITUTION list of Institutions connected with the paper SOURCE publiction source VOLUME volume (for journal articles) ISSUE issue (for journal articles) PAGES page numbers referring to PUBLISHER document publisher LANGUAGE document language PUBLDATE publishing date PUBLYEAR publishing year PUBLPLACE publishing place PUBLCOUNTRY publishing country IDENTIFIER list of additional identifiers (pmid, pmcid, nlmid,...) DOI Document Object identifier ISSN International Standard Serial Number EISSN Electronic International Standard Serial Number PISSN Print International Standard Serial Number DATABASE Source Database from wich LIVIVO collected the document (MEDLINE,NLM,AGRIS,..) DOCUMENTURL URL for accessing document MESH list of MESH-terms KEYWORDS additional keywords CHEM list of chemical substances The dataset is provided in jsonlines-format. Download the LIVIVO-testset here: https://th-koeln.sciebo.de/s/OBm0NLEwz1RYl9N/download?path=%2Flivivo%2Fdocuments&files=livivo_testset.jsonl 4. Forking and cloning STELLA-microservice Template Before you start working on your own ranking-system, you should fork our template. Navigate with your browser to our template repository https://github.com/stella-project/stella-micro-template and click the \"fork\"-button on the top right. This will create a fork in your personal github-account. Now navigate to your working directory and run the following command to clone the forked repository to your local system. $ git clone https://github.com/your-username/stella-micro-template.git 5. Adding dataset to your local environment Please download the LIVIVO-testset here: https://th-koeln.sciebo.de/s/OBm0NLEwz1RYl9N/download?path=%2Flivivo%2Fdocuments&files=livivo_testset.jsonl Place the file into stella-micro-template/data/livivo/datasets. If these subfolders do not exist, create them. \u251c\u2500\u2500 stella-micro-template \u2502 \u251c\u2500\u2500 data \u2502 \u2502 \u251c\u2500\u2500 livivo \u2502 \u2502 \u251c\u2500\u2500 documents \u2502 \u2502 \u251c\u2500\u2500 livivo_testset.jsonl 6. REST-Endpoints with Flask To connect your system with STELLA, your container has to provide REST-endpoints according to the STELLA-interface. Your system should provide three endpoints. First of all, your system has to implement an indexing-endpoint. This endpoint is called when your system is used for the first time. It builds a search-index from the data provided by the site. The ranking-endpoint must return an ordered list of document-ids in JSON format. If you provide these endpoints, your results will be integrated seamlessly into the sites\u2019 pages. The test-endpoint is, as you may have guessed, for testing if your container is up and running. It just displays the name of your container. GET /index Starts indexing data, when starting ranking-system for the first time GET /ranking?query=<string:qstr>&page=<int:pnum>&rpp=<int:rppnum> Returns an ordered list of document-ids in JSON-Format GET /test This Endpoints is for testing purposes and just prints the name of your container For a more detailled explanation of the API-Interface please visit our API-interface-documentation . All these endpoints are already existing in the template. Please have a look into the file app.py . Plese don't do any changes in that file. from flask import Flask, request, jsonify, redirect from systems import Ranker, Recommender app = Flask(__name__) ranker = Ranker() recommender = Recommender() @app.route('/') def redirect_to_test(): return redirect(\"/test\", code=302) @app.route('/test', methods=[\"GET\"]) def test(): return 'Container is running', 200 @app.route('/index', methods=[\"GET\"]) def index(): ranker.index() recommender.index() return 'Indexing done!', 200 @app.route('/ranking', methods=[\"GET\"]) def ranking(): query = request.args.get('query', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = ranker.rank_publications(query, page, rpp) return jsonify(response) @app.route('/recommendation/datasets', methods=[\"GET\"]) def rec_data(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_datasets(item_id, page, rpp) return jsonify(response) @app.route('/recommendation/publications', methods=[\"GET\"]) def rec_pub(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_publications(item_id, page, rpp) return jsonify(response) if __name__ == '__main__': app.run(host='0.0.0.0', port=5000, debug=True) You might have registered some endpoints for building recommendation-systems. Since we are only building a ranking-system, please ignore these endpoints for now. 7. Indexing data Let's start indexing the data from \"livivo_test.jsonl\". This file contains data in jsonlines format, which means, each line is an individual json-object, which represents a single document. Open the file systems.py . This file contains to classes: Ranker and Recommender. As the name says, the first one is for implementing a rankings, the second one for recommender-systems. In this tutorial we will only change the Ranker-Class. At first, we will implement the code for indexing documents. We will read the documents with the help of the jsonlines-package. Don't forget to import the package first. For the sake of simplicity, we will just extract the unique identifier of any document and store them in the python built-in type \"list\". At a later stage, when you work with the full corpus of LIVIVO, which contains more than 60 mio documents, you should switch to a more sophisticated Index. You will change the method index(self) so it reads the documents from livivo_testset.jsonl The Ranker-Class in your file systems.py should now look like this: import jsonlines class Ranker(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/livivo/documents/livivo_testset.jsonl') as reader: for obj in reader: self.idx.append(obj['DBRECORDID']) def rank_publications(self, query, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'query': query, 'itemlist': itemlist, 'num_found': len(itemlist) } 8. ranking documents (shuffled) Now we will implement our personal ranking-algorithm. To keep it simple, our ranking-algorithm picks just a number of random documents. This will give you an idea, how it works and enables you to implement some smart ranking-algorithms after this tutorial. For picking some random entries from our item-list, we can use the choice-method from the random package which is part of the python library and doese not need any installation (i.e. you do not need to add it to the requirements.txt file). You will be changing the first line of the method rank_publications(self, query, page, rpp) to get a randomized item list itemlist = random.choices(self.idx, k=rpp) The Ranker-Class in your file systems.py should now look like this: import jsonlines import random class Ranker(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/livivo/documents/livivo_testset.jsonl') as reader: for obj in reader: self.idx.append(obj['DBRECORDID']) def rank_publications(self, query, page, rpp): itemlist = random.choices(self.idx, k=rpp) return { 'page': page, 'rpp': rpp, 'query': query, 'itemlist': itemlist, 'num_found': len(itemlist) } If you decide to use external packages, please add them to the file requirements.py . In our example, we decided to use the package jsonlines . Your file requirements.py should now look like this flask jsonlines 9. setup virtual environment We are now ready to run your application. Before pushing your code to github, you should verify, that everything works as expected. To do so, you should create a virtual-environment, install the necessary dependencies there and run your Ranker on your local machine. Python IDEs (like PyCharm) offer functionalities to create a virtual python environment inside your project. Since we don't know which IDE you are using, we show you, how to create Virtual-Environment manually. Inside the directory of your cloned-repository, please run this command. On Linux and MacOS $ python3 -m venv venv On Windows $ py -m venv venv This creates a virtual python environment in the folder venv . To activate and work with your virtual python environment, please run this commadn: On Linux and MacOs $ source venv/bin/activate On Windows .\\venv\\Scripts\\activate Now, you have to make sure, that all necessary packages are available in your virtual python environment. pip install -r requirements.txt Don't push the folder venv which contains the virtual python environment to your github-repository. It's just for testing your Ranker on your local machine. 10. run ranker in virtual environment In your activated virtual environment, start the application. $ python app.py You will get some messages on the shell, indicating, that your Flask-App is running. Now we can do some checks to see if everything works as it should. Please open your browser and access the following address http://0.0.0.0:5000/test (you might need to use http://localhost:5000/test in Windows). Your browser should reply with the message \"Container is running\". This means, Flask is running and serving at Port 5000. Do not worry if your try http://0.0.0.0:5000/ as that entry point is not implemented (i.e. it is expected that you will get an error). Now we want to start indexing documents with our ranker. Please access the following address with your browser http://0.0.0.0:5000/index (or http://localhost:5000/index in Windows). This may take some time, when indexing a big collection. After indexing was successful, your browser should replay with \"Indexing done!\". We are ready to send queries to our ranking-system and get results. Access the following address with your browser http://0.0.0.0:5000/ranking?query=test (you might need to use http://localhost:5000/ranking?query=test in Windows). Your browser will reply with a JSON-Document, that look like to this (itemlist will be different, because the results are randomized): { \"itemlist\": [ \"M7064959\", \"NLM7513803\", \"NLM8300642A\", \"AGRISUS201600020713\", \"AGRISFR2016217161\", \"NLM26061140R\", \"NLM101220129\", \"M28128407\", \"AGRISUS201400054734\", \"NLM101070554\", \"NLM101230052\", \"M17665832\", \"M28313204\", \"NLM9412462\", \"NLM101068566\", \"AGRISJP2009005254\", \"NLM101173006\", \"M4793495\", \"M2965586\", \"M2082902\" ], \"num_found\": 20, \"page\": 0, \"query\": \"test\", \"rpp\": 20 } Congratulations! Your ranker is running! We can now start to build a dockerized version and run unit-tests! 11. Build docker-contaner and run unit-tests You are now ready to build your ranker as a docker-container and run unit-tests to check if everything is working as expected, before pushing your code back to github. Navigate to the folder test . Make sure, you still have your virtual environment activated and stopped your ranking application. First, install the python-dependencies needed for running the unit-tests: $ pip install -r requirements.txt Next, we are ready to build and run your ranker as docker-container. Please run the python-script \"docker_build_run.py\". $ python docker_build_run.py Open your browser and please verifiy, if the endpoints are accessible: - http://0.0.0.0:5000/test (http://localhost:5000/test in Windows) - http://0.0.0.0:5000/index (http://localhost:5000/index in Windows) - http://0.0.0.0:5000/ranking?query=test (http://localhost:5000/ranking?query=test in Windows) Now we can run the unit-tests: $ python test_ranking.py This will run 6 different tests, which your container has to pass, before it can be integrated into STELLA The Script should print the message \"OK\". If you are using Windows, make sure you target 'localhost' rather than '0.0.0.0' on the IP variable in the test (i.e. IP = 'localhost' for Windows; for other OS IP = '0.0.0.0. should work). 12. push your changes to github Now you are ready to push your ranker back to github. Add the changed files to the the staging area. git add systems.py requirements.txt Save the changes to you local repository. git commit -m \"add systems and requirements\" Update remote branch with local commit. git push origin main Your ranker is now ready for integration into the STELLA-infrastructure. Please make sure, that the visibility of your repository is set to \"public\".","title":"Tutorial: Ranking micro-service"},{"location":"guides/participants-ranking/#how-to-integrate-a-ranking-micro-service","text":"","title":"How to integrate a ranking micro-service"},{"location":"guides/participants-ranking/#1-introduction","text":"The STELLA-framework enables participants to run and evaluate ranking and recommendation-systems in a Living-Lab scenario. The heart of STELLA-framework is the STELLA application, which is implemented as a a multi-container-application (MCA) by the sites (the search-engines) and handles communication between the site and participant-containers. This means every participant-system must be deployed as a docker image, which runs as a container inside STELLA application. In principle you have full freedom in choice of programming language and software tools. Your container only has to satisfy the constraints of a predefined REST-API. If you want to learn more about STELLA, please see our blog posts . This tutorial will guide you step-by-step through the process of integrating a ranking microservice into STELLA-infrastructure. You will learn how to build your own dockerized ranking-system with python. For this purpose we will use a document subset from the LIVIVO search engine. To give you a head start, we prepared a code template. That means, you just have to write a few lines of code to get your ranking-system running.","title":"1. Introduction"},{"location":"guides/participants-ranking/#2-prerequisites","text":"Before starting this tutorial, make sure all requirements in the README.md are fulfilled.","title":"2. Prerequisites"},{"location":"guides/participants-ranking/#3-livivo-dataset","text":"LIVIVO is an interdisciplinary search engine for literature and information in the field of life sciences. It is run by ZB MED \u2013 Information Centre for Life Sciences. LIVIVO draws on relevant scientific information from the ZB MED subject areas of medicine, health, nutrition, and environmental and agricultural sciences. (https://www.livivo.de/app/misc/help/about) In this tutorial we will work with a small subset of LIVIVO (30000 documents). See the following table for an explanation of fields. field description DBRECORDID primary document key TITLE document title ABSTRACT document abstract AUTHOR list of authors INSTITUTION list of Institutions connected with the paper SOURCE publiction source VOLUME volume (for journal articles) ISSUE issue (for journal articles) PAGES page numbers referring to PUBLISHER document publisher LANGUAGE document language PUBLDATE publishing date PUBLYEAR publishing year PUBLPLACE publishing place PUBLCOUNTRY publishing country IDENTIFIER list of additional identifiers (pmid, pmcid, nlmid,...) DOI Document Object identifier ISSN International Standard Serial Number EISSN Electronic International Standard Serial Number PISSN Print International Standard Serial Number DATABASE Source Database from wich LIVIVO collected the document (MEDLINE,NLM,AGRIS,..) DOCUMENTURL URL for accessing document MESH list of MESH-terms KEYWORDS additional keywords CHEM list of chemical substances The dataset is provided in jsonlines-format. Download the LIVIVO-testset here: https://th-koeln.sciebo.de/s/OBm0NLEwz1RYl9N/download?path=%2Flivivo%2Fdocuments&files=livivo_testset.jsonl","title":"3. LIVIVO Dataset"},{"location":"guides/participants-ranking/#4-forking-and-cloning-stella-microservice-template","text":"Before you start working on your own ranking-system, you should fork our template. Navigate with your browser to our template repository https://github.com/stella-project/stella-micro-template and click the \"fork\"-button on the top right. This will create a fork in your personal github-account. Now navigate to your working directory and run the following command to clone the forked repository to your local system. $ git clone https://github.com/your-username/stella-micro-template.git","title":"4. Forking and cloning STELLA-microservice Template"},{"location":"guides/participants-ranking/#5-adding-dataset-to-your-local-environment","text":"Please download the LIVIVO-testset here: https://th-koeln.sciebo.de/s/OBm0NLEwz1RYl9N/download?path=%2Flivivo%2Fdocuments&files=livivo_testset.jsonl Place the file into stella-micro-template/data/livivo/datasets. If these subfolders do not exist, create them. \u251c\u2500\u2500 stella-micro-template \u2502 \u251c\u2500\u2500 data \u2502 \u2502 \u251c\u2500\u2500 livivo \u2502 \u2502 \u251c\u2500\u2500 documents \u2502 \u2502 \u251c\u2500\u2500 livivo_testset.jsonl","title":"5. Adding dataset to your local environment"},{"location":"guides/participants-ranking/#6-rest-endpoints-with-flask","text":"To connect your system with STELLA, your container has to provide REST-endpoints according to the STELLA-interface. Your system should provide three endpoints. First of all, your system has to implement an indexing-endpoint. This endpoint is called when your system is used for the first time. It builds a search-index from the data provided by the site. The ranking-endpoint must return an ordered list of document-ids in JSON format. If you provide these endpoints, your results will be integrated seamlessly into the sites\u2019 pages. The test-endpoint is, as you may have guessed, for testing if your container is up and running. It just displays the name of your container. GET /index Starts indexing data, when starting ranking-system for the first time GET /ranking?query=<string:qstr>&page=<int:pnum>&rpp=<int:rppnum> Returns an ordered list of document-ids in JSON-Format GET /test This Endpoints is for testing purposes and just prints the name of your container For a more detailled explanation of the API-Interface please visit our API-interface-documentation . All these endpoints are already existing in the template. Please have a look into the file app.py . Plese don't do any changes in that file. from flask import Flask, request, jsonify, redirect from systems import Ranker, Recommender app = Flask(__name__) ranker = Ranker() recommender = Recommender() @app.route('/') def redirect_to_test(): return redirect(\"/test\", code=302) @app.route('/test', methods=[\"GET\"]) def test(): return 'Container is running', 200 @app.route('/index', methods=[\"GET\"]) def index(): ranker.index() recommender.index() return 'Indexing done!', 200 @app.route('/ranking', methods=[\"GET\"]) def ranking(): query = request.args.get('query', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = ranker.rank_publications(query, page, rpp) return jsonify(response) @app.route('/recommendation/datasets', methods=[\"GET\"]) def rec_data(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_datasets(item_id, page, rpp) return jsonify(response) @app.route('/recommendation/publications', methods=[\"GET\"]) def rec_pub(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_publications(item_id, page, rpp) return jsonify(response) if __name__ == '__main__': app.run(host='0.0.0.0', port=5000, debug=True) You might have registered some endpoints for building recommendation-systems. Since we are only building a ranking-system, please ignore these endpoints for now.","title":"6. REST-Endpoints with Flask"},{"location":"guides/participants-ranking/#7-indexing-data","text":"Let's start indexing the data from \"livivo_test.jsonl\". This file contains data in jsonlines format, which means, each line is an individual json-object, which represents a single document. Open the file systems.py . This file contains to classes: Ranker and Recommender. As the name says, the first one is for implementing a rankings, the second one for recommender-systems. In this tutorial we will only change the Ranker-Class. At first, we will implement the code for indexing documents. We will read the documents with the help of the jsonlines-package. Don't forget to import the package first. For the sake of simplicity, we will just extract the unique identifier of any document and store them in the python built-in type \"list\". At a later stage, when you work with the full corpus of LIVIVO, which contains more than 60 mio documents, you should switch to a more sophisticated Index. You will change the method index(self) so it reads the documents from livivo_testset.jsonl The Ranker-Class in your file systems.py should now look like this: import jsonlines class Ranker(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/livivo/documents/livivo_testset.jsonl') as reader: for obj in reader: self.idx.append(obj['DBRECORDID']) def rank_publications(self, query, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'query': query, 'itemlist': itemlist, 'num_found': len(itemlist) }","title":"7. Indexing data"},{"location":"guides/participants-ranking/#8-ranking-documents-shuffled","text":"Now we will implement our personal ranking-algorithm. To keep it simple, our ranking-algorithm picks just a number of random documents. This will give you an idea, how it works and enables you to implement some smart ranking-algorithms after this tutorial. For picking some random entries from our item-list, we can use the choice-method from the random package which is part of the python library and doese not need any installation (i.e. you do not need to add it to the requirements.txt file). You will be changing the first line of the method rank_publications(self, query, page, rpp) to get a randomized item list itemlist = random.choices(self.idx, k=rpp) The Ranker-Class in your file systems.py should now look like this: import jsonlines import random class Ranker(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/livivo/documents/livivo_testset.jsonl') as reader: for obj in reader: self.idx.append(obj['DBRECORDID']) def rank_publications(self, query, page, rpp): itemlist = random.choices(self.idx, k=rpp) return { 'page': page, 'rpp': rpp, 'query': query, 'itemlist': itemlist, 'num_found': len(itemlist) } If you decide to use external packages, please add them to the file requirements.py . In our example, we decided to use the package jsonlines . Your file requirements.py should now look like this flask jsonlines","title":"8. ranking documents (shuffled)"},{"location":"guides/participants-ranking/#9-setup-virtual-environment","text":"We are now ready to run your application. Before pushing your code to github, you should verify, that everything works as expected. To do so, you should create a virtual-environment, install the necessary dependencies there and run your Ranker on your local machine. Python IDEs (like PyCharm) offer functionalities to create a virtual python environment inside your project. Since we don't know which IDE you are using, we show you, how to create Virtual-Environment manually. Inside the directory of your cloned-repository, please run this command. On Linux and MacOS $ python3 -m venv venv On Windows $ py -m venv venv This creates a virtual python environment in the folder venv . To activate and work with your virtual python environment, please run this commadn: On Linux and MacOs $ source venv/bin/activate On Windows .\\venv\\Scripts\\activate Now, you have to make sure, that all necessary packages are available in your virtual python environment. pip install -r requirements.txt Don't push the folder venv which contains the virtual python environment to your github-repository. It's just for testing your Ranker on your local machine.","title":"9. setup virtual environment"},{"location":"guides/participants-ranking/#10-run-ranker-in-virtual-environment","text":"In your activated virtual environment, start the application. $ python app.py You will get some messages on the shell, indicating, that your Flask-App is running. Now we can do some checks to see if everything works as it should. Please open your browser and access the following address http://0.0.0.0:5000/test (you might need to use http://localhost:5000/test in Windows). Your browser should reply with the message \"Container is running\". This means, Flask is running and serving at Port 5000. Do not worry if your try http://0.0.0.0:5000/ as that entry point is not implemented (i.e. it is expected that you will get an error). Now we want to start indexing documents with our ranker. Please access the following address with your browser http://0.0.0.0:5000/index (or http://localhost:5000/index in Windows). This may take some time, when indexing a big collection. After indexing was successful, your browser should replay with \"Indexing done!\". We are ready to send queries to our ranking-system and get results. Access the following address with your browser http://0.0.0.0:5000/ranking?query=test (you might need to use http://localhost:5000/ranking?query=test in Windows). Your browser will reply with a JSON-Document, that look like to this (itemlist will be different, because the results are randomized): { \"itemlist\": [ \"M7064959\", \"NLM7513803\", \"NLM8300642A\", \"AGRISUS201600020713\", \"AGRISFR2016217161\", \"NLM26061140R\", \"NLM101220129\", \"M28128407\", \"AGRISUS201400054734\", \"NLM101070554\", \"NLM101230052\", \"M17665832\", \"M28313204\", \"NLM9412462\", \"NLM101068566\", \"AGRISJP2009005254\", \"NLM101173006\", \"M4793495\", \"M2965586\", \"M2082902\" ], \"num_found\": 20, \"page\": 0, \"query\": \"test\", \"rpp\": 20 } Congratulations! Your ranker is running! We can now start to build a dockerized version and run unit-tests!","title":"10. run ranker in virtual environment"},{"location":"guides/participants-ranking/#11-build-docker-contaner-and-run-unit-tests","text":"You are now ready to build your ranker as a docker-container and run unit-tests to check if everything is working as expected, before pushing your code back to github. Navigate to the folder test . Make sure, you still have your virtual environment activated and stopped your ranking application. First, install the python-dependencies needed for running the unit-tests: $ pip install -r requirements.txt Next, we are ready to build and run your ranker as docker-container. Please run the python-script \"docker_build_run.py\". $ python docker_build_run.py Open your browser and please verifiy, if the endpoints are accessible: - http://0.0.0.0:5000/test (http://localhost:5000/test in Windows) - http://0.0.0.0:5000/index (http://localhost:5000/index in Windows) - http://0.0.0.0:5000/ranking?query=test (http://localhost:5000/ranking?query=test in Windows) Now we can run the unit-tests: $ python test_ranking.py This will run 6 different tests, which your container has to pass, before it can be integrated into STELLA The Script should print the message \"OK\". If you are using Windows, make sure you target 'localhost' rather than '0.0.0.0' on the IP variable in the test (i.e. IP = 'localhost' for Windows; for other OS IP = '0.0.0.0. should work).","title":"11. Build docker-contaner and run unit-tests"},{"location":"guides/participants-ranking/#12-push-your-changes-to-github","text":"Now you are ready to push your ranker back to github. Add the changed files to the the staging area. git add systems.py requirements.txt Save the changes to you local repository. git commit -m \"add systems and requirements\" Update remote branch with local commit. git push origin main Your ranker is now ready for integration into the STELLA-infrastructure. Please make sure, that the visibility of your repository is set to \"public\".","title":"12. push your changes to github"},{"location":"guides/participants-recommender-publications/","text":"How to integrate a micro-service for recommending publications 1. Introduction The STELLA-framework enables participants to run and evaluate ranking and recommender-systems in a Living-Lab scenario. The heart of STELLA-framework is the STELLA application, which is implemented as a a multi-container-application (MCA) by the sites (the search-engines) and handles communication between the site and participant-containers. This means every participant-system must be deployed as a docker image, which runs as a container inside STELLA application. In principle you have full freedom in choice of programming language and software tools. Your container only has to satisfy the constraints of a predefined REST-API. If you want to learn more about STELLA, please see our blog posts . This tutorial will guide you step-by-step through the process of integrating a recommendation microservice into STELLA-infrastructure. You will learn how to build your own dockerized recommender-system for publication with python. For this purpose we will use a document subset from the LIVIVO search engine. To give you a head start, we prepared a code template. That means, you just have to write a few lines of code to get your recommender-system running. 2. Prerequisites Before starting this tutorial, make sure all requirements in the README.md are fulfilled. 3. LIVIVO Dataset LIVIVO is an interdisciplinary search engine for literature and information in the field of life sciences. It is run by ZB MED \u2013 Information Centre for Life Sciences. LIVIVO draws on relevant scientific information from the ZB MED subject areas of medicine, health, nutrition, and environmental and agricultural sciences. (https://www.livivo.de/app/misc/help/about) In this tutorial we will work with a small subset of LIVIVO (30000 documents). See the following table for an explanation of fields. field description DBRECORDID primary document key TITLE document title ABSTRACT document abstract AUTHOR list of authors INSTITUTION list of Institutions connected with the paper SOURCE publiction source VOLUME volume (for journal articles) ISSUE issue (for journal articles) PAGES page numbers referring to PUBLISHER document publisher LANGUAGE document language PUBLDATE publishing date PUBLYEAR publishing year PUBLPLACE publishing place PUBLCOUNTRY publishing country IDENTIFIER list of additional identifiers (pmid, pmcid, nlmid,...) DOI Document Object identifier ISSN International Standard Serial Number EISSN Electronic International Standard Serial Number PISSN Print International Standard Serial Number DATABASE Source Database from wich LIVIVO collected the document (MEDLINE,NLM,AGRIS,..) DOCUMENTURL URL for accessing document MESH list of MESH-terms KEYWORDS additional keywords CHEM list of chemical substances The dataset is provided in jsonlines-format. Download the LIVIVO-testset here: LIVIVO test-set 4. Forking and cloning STELLA-microservice Template Before you start working on your own recommender-system, you should fork our template. Navigate with your browser to our template repository https://github.com/stella-project/stella-micro-template and click the \"fork\"-button on the top right. This will create a fork in your personal github-account. Now navigate to your working directory and run the following command to clone the forked repository to your local system. $ git clone https://github.com/your-username/stella-micro-template.git 5. Adding dataset to your local environment Please download the LIVIVO-testset here: LIVIVO test-set Place the file into stella-micro-template/data/livivo/datasets. If these subfolders do not exist, create them. \u251c\u2500\u2500 stella-micro-template \u2502 \u251c\u2500\u2500 data \u2502 \u2502 \u251c\u2500\u2500 livivo \u2502 \u2502 \u251c\u2500\u2500 documents \u2502 \u2502 \u251c\u2500\u2500 livivo_testset.jsonl 6. REST-Endpoints with Flask To connect your system with STELLA, your container has to provide REST-endpoints according to the STELLA-interface. Your system should provide three endpoints. First of all, your system has to implement an indexing-endpoint. This endpoint is called when your system is used for the first time. It builds a search-index from the data provided by the site. The recommendation-endpoint must return an ordered list of document-ids in JSON format. If you provide these endpoints, your results will be integrated seamlessly into the sites\u2019 pages. The test-endpoint is, as you may have guessed, for testing if your container is up and running. It just displays the name of your container. GET /index Starts indexing data, when starting ranking-system for the first time GET /recommendadtion/publications?item_id=<string:item_id>&page=<int:pnum>&rpp=<int:rppnum> Returns an ordered list of document-ids in JSON-Format GET /test This Endpoints is for testing purposes and just prints the name of your container For a more detailled explanation of the API-Interface please visit our API-interface-documentation . All these endpoints are already existing in the template. Please have a look into the file app.py . Plese don't do any changes in that file. from flask import Flask, request, jsonify, redirect from systems import Ranker, Recommender app = Flask(__name__) ranker = Ranker() recommender = Recommender() @app.route('/') def redirect_to_test(): return redirect(\"/test\", code=302) @app.route('/test', methods=[\"GET\"]) def test(): return 'Container is running', 200 @app.route('/index', methods=[\"GET\"]) def index(): ranker.index() recommender.index() return 'Indexing done!', 200 @app.route('/ranking', methods=[\"GET\"]) def ranking(): query = request.args.get('query', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = ranker.rank_publications(query, page, rpp) return jsonify(response) @app.route('/recommendation/datasets', methods=[\"GET\"]) def rec_data(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_datasets(item_id, page, rpp) return jsonify(response) @app.route('/recommendation/publications', methods=[\"GET\"]) def rec_pub(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_publications(item_id, page, rpp) return jsonify(response) if __name__ == '__main__': app.run(host='0.0.0.0', port=5000, debug=True) You might have registered some endpoints for building ranking-systems. Since we are only building a recommendation-system, please ignore these endpoints for now. 7. Indexing data Let's start indexing the data from \"livivo_test.jsonl\". This file contains data in jsonlines format, which means, each line is an individual json-object, which represents a single document. Open the file systems.py . This file contains two classes: Ranker and Recommender. As the name says, the first one is for implementing a ranking, the second one for recommender-systems. In this tutorial we will only change the Recommender-Class. At first, we will implement the code for indexing documents. We will read the documents with the help of the jsonlines-package. Don't forget to import the package first. For the sake of simplicity, we will just extract the unique identifier of any document and store them in the python built-in type \"list\". At a later stage, when you work with the full corpus of LIVIVO, which contains more than 60 mio documents, you should switch to a more sophisticated index. You will change the method index(self) so it reads the documents from livivo_testset.jsonl The Ranker-Class in your file systems.py should now look like this: import jsonlines class Recommender(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/livivo/documents/livivo_testset.jsonl') as reader: for obj in reader: self.idx.append(obj['DBRECORDID']) def recommend_datasets(self, item_id, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } def recommend_publications(self, item_id, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } 8. recommend documents (shuffled) Now we will implement our personal algorithm for recommending publications. To keep it simple, our recommender-algorithm picks just a number of random documents. This will give you an idea, how it works and enables you to implement some smart recommender-algorithms after this tutorial. For picking some random entries from our item-list, we can use the choice-method from the random package which is part of the python library and does not need any installation (i.e. you do not need to add it to the requirements.txt file). You will be changing the first line of the method recommend_publications(self, query, page, rpp) to get a randomized item list itemlist = random.choices(self.idx, k=rpp) The Recommender-Cass in your file systems.py should now look like this: import jsonlines import random class Recommender(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/livivo/documents/livivo_testset.jsonl') as reader: for obj in reader: self.idx.append(obj['DBRECORDID']) def recommend_datasets(self, item_id, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } def recommend_publications(self, item_id, page, rpp): itemlist = random.choices(self.idx, k=rpp) return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } If you decide to use external packages, please add them to the file requirements.py . In our example, we decided to use the package jsonlines . Your file requirements.py should now look like this flask jsonlines 9. setup virtual environment We are now ready to run your application. Before pushing your code to github, you should verify, that everything works as expected. To do so, you should create a virtual-environment, install the necessary dependencies there and run your Ranker on your local machine. Python IDEs (like PyCharm) offer functionalities to create a virtual python environment inside your project. Since we don't know which IDE you are using, we show you, how to create Virtual-Environment manually. Inside the directory of your cloned-repository, please run this command. On Linux and MacOS $ python3 -m venv venv On Windows $ py -m venv venv This creates a virtual python environment in the folder venv . To activate and work with your virtual python environment, please run this commadn: On Linux and MacOs $ source venv/bin/activate On Windows .\\venv\\Scripts\\activate Now, you have to make sure, that all necessary packages are available in your virtual python environment. pip install -r requirements.txt Don't push the folder venv which contains the virtual python environment to your github-repository. It's just for testing your Recommender on your local machine. 10. run ranker in virtual environment In your activated virtual environment, start the application. $ python app.py You will get some messages on the shell, indicating, that your Flask-App is running. Now we can do some checks to see if everything works as it should. Please open your browser and access the following address http://0.0.0.0:5000/test (you might need to use http://localhost:5000/test in Windows). Your browser should reply with the message \"Container is running\". This means, Flask is running and serving at Port 5000. Do not worry if your try http://0.0.0.0:5000/ as that entry point is not implemented (i.e. it is expected that you will get an error). Now we want to start indexing documents with our recommender. Please access the following address with your browser http://0.0.0.0:5000/index (or http://localhost:5000/index in Windows). This may take some time, when indexing a big collection. After indexing was successful, your browser should replay with \"Indexing done!\". We are ready to send queries to our ranking-system and get results. Access the following address with your browser http://0.0.0.0:5000/recommendation/publication?item_id=M5339676 (you might need to use http://localhost:5000/ranking?query=test in Windows). Please make sure using an item_id that exists in the indexed dataset, otherwise you'll may not get any results. Your browser will reply with a JSON-Document, that looks like this (itemlist will be different, because the results are randomized): { \"itemlist\": [ \"M7064959\", \"NLM7513803\", \"NLM8300642A\", \"AGRISUS201600020713\", \"AGRISFR2016217161\", \"NLM26061140R\", \"NLM101220129\", \"M28128407\", \"AGRISUS201400054734\", \"NLM101070554\", \"NLM101230052\", \"M17665832\", \"M28313204\", \"NLM9412462\", \"NLM101068566\", \"AGRISJP2009005254\", \"NLM101173006\", \"M4793495\", \"M2965586\", \"M2082902\" ], \"num_found\": 20, \"page\": 0, \"query\": \"test\", \"rpp\": 20 } Congratulations! Your ranker is running! We can now start to build a dockerized version and run unit-tests! 11. Build docker-container and run unit-tests You are now ready to build your ranker as a docker-container and run unit-tests to check if everything is working as expected, before pushing your code back to github. Navigate to the folder test . Make sure, you still have your virtual environment activated and stopped your ranking application. First, install the python-dependencies needed for running the unit-tests: $ pip install -r requirements.txt Next, we are ready to build and run your ranker as docker-container. Please run the python-script \"docker_build_run.py\". $ python docker_build_run.py Open your browser and please verifiy, if the endpoints are accessible: - http://0.0.0.0:5000/test (http://localhost:5000/test in Windows) - http://0.0.0.0:5000/index (http://localhost:5000/index in Windows) - http://0.0.0.0:5000/recommendation/publications?item_id=M8498126 (http://localhost:5000/recommendation/publications?item_id=M8498126 in Windows) Now we can run the unit-tests: $ python test_recommendation_publications.py This will run 6 different tests, which your container has to pass, before it can be integrated into STELLA The Script should print the message \"OK\". If you are using Windows, make sure you target 'localhost' rather than '0.0.0.0' on the IP variable in the test (i.e. IP = 'localhost' for Windows; for other OS IP = '0.0.0.0. should work). 12. push your changes to github Now you are ready to push your ranker back to github. Add the changed files to the the staging area. git add systems.py requirements.txt Save the changes to you local repository. git commit -m \"add systems and requirements\" Update remote branch with local commit. git push origin main Your recommender-system is now ready for integration into the STELLA-infrastructure. Please make sure, that the visibility of your repository is set to \"public\".","title":"How to integrate a micro-service for recommending publications"},{"location":"guides/participants-recommender-publications/#how-to-integrate-a-micro-service-for-recommending-publications","text":"","title":"How to integrate a micro-service for recommending publications"},{"location":"guides/participants-recommender-publications/#1-introduction","text":"The STELLA-framework enables participants to run and evaluate ranking and recommender-systems in a Living-Lab scenario. The heart of STELLA-framework is the STELLA application, which is implemented as a a multi-container-application (MCA) by the sites (the search-engines) and handles communication between the site and participant-containers. This means every participant-system must be deployed as a docker image, which runs as a container inside STELLA application. In principle you have full freedom in choice of programming language and software tools. Your container only has to satisfy the constraints of a predefined REST-API. If you want to learn more about STELLA, please see our blog posts . This tutorial will guide you step-by-step through the process of integrating a recommendation microservice into STELLA-infrastructure. You will learn how to build your own dockerized recommender-system for publication with python. For this purpose we will use a document subset from the LIVIVO search engine. To give you a head start, we prepared a code template. That means, you just have to write a few lines of code to get your recommender-system running.","title":"1. Introduction"},{"location":"guides/participants-recommender-publications/#2-prerequisites","text":"Before starting this tutorial, make sure all requirements in the README.md are fulfilled.","title":"2. Prerequisites"},{"location":"guides/participants-recommender-publications/#3-livivo-dataset","text":"LIVIVO is an interdisciplinary search engine for literature and information in the field of life sciences. It is run by ZB MED \u2013 Information Centre for Life Sciences. LIVIVO draws on relevant scientific information from the ZB MED subject areas of medicine, health, nutrition, and environmental and agricultural sciences. (https://www.livivo.de/app/misc/help/about) In this tutorial we will work with a small subset of LIVIVO (30000 documents). See the following table for an explanation of fields. field description DBRECORDID primary document key TITLE document title ABSTRACT document abstract AUTHOR list of authors INSTITUTION list of Institutions connected with the paper SOURCE publiction source VOLUME volume (for journal articles) ISSUE issue (for journal articles) PAGES page numbers referring to PUBLISHER document publisher LANGUAGE document language PUBLDATE publishing date PUBLYEAR publishing year PUBLPLACE publishing place PUBLCOUNTRY publishing country IDENTIFIER list of additional identifiers (pmid, pmcid, nlmid,...) DOI Document Object identifier ISSN International Standard Serial Number EISSN Electronic International Standard Serial Number PISSN Print International Standard Serial Number DATABASE Source Database from wich LIVIVO collected the document (MEDLINE,NLM,AGRIS,..) DOCUMENTURL URL for accessing document MESH list of MESH-terms KEYWORDS additional keywords CHEM list of chemical substances The dataset is provided in jsonlines-format. Download the LIVIVO-testset here: LIVIVO test-set","title":"3. LIVIVO Dataset"},{"location":"guides/participants-recommender-publications/#4-forking-and-cloning-stella-microservice-template","text":"Before you start working on your own recommender-system, you should fork our template. Navigate with your browser to our template repository https://github.com/stella-project/stella-micro-template and click the \"fork\"-button on the top right. This will create a fork in your personal github-account. Now navigate to your working directory and run the following command to clone the forked repository to your local system. $ git clone https://github.com/your-username/stella-micro-template.git","title":"4. Forking and cloning STELLA-microservice Template"},{"location":"guides/participants-recommender-publications/#5-adding-dataset-to-your-local-environment","text":"Please download the LIVIVO-testset here: LIVIVO test-set Place the file into stella-micro-template/data/livivo/datasets. If these subfolders do not exist, create them. \u251c\u2500\u2500 stella-micro-template \u2502 \u251c\u2500\u2500 data \u2502 \u2502 \u251c\u2500\u2500 livivo \u2502 \u2502 \u251c\u2500\u2500 documents \u2502 \u2502 \u251c\u2500\u2500 livivo_testset.jsonl","title":"5. Adding dataset to your local environment"},{"location":"guides/participants-recommender-publications/#6-rest-endpoints-with-flask","text":"To connect your system with STELLA, your container has to provide REST-endpoints according to the STELLA-interface. Your system should provide three endpoints. First of all, your system has to implement an indexing-endpoint. This endpoint is called when your system is used for the first time. It builds a search-index from the data provided by the site. The recommendation-endpoint must return an ordered list of document-ids in JSON format. If you provide these endpoints, your results will be integrated seamlessly into the sites\u2019 pages. The test-endpoint is, as you may have guessed, for testing if your container is up and running. It just displays the name of your container. GET /index Starts indexing data, when starting ranking-system for the first time GET /recommendadtion/publications?item_id=<string:item_id>&page=<int:pnum>&rpp=<int:rppnum> Returns an ordered list of document-ids in JSON-Format GET /test This Endpoints is for testing purposes and just prints the name of your container For a more detailled explanation of the API-Interface please visit our API-interface-documentation . All these endpoints are already existing in the template. Please have a look into the file app.py . Plese don't do any changes in that file. from flask import Flask, request, jsonify, redirect from systems import Ranker, Recommender app = Flask(__name__) ranker = Ranker() recommender = Recommender() @app.route('/') def redirect_to_test(): return redirect(\"/test\", code=302) @app.route('/test', methods=[\"GET\"]) def test(): return 'Container is running', 200 @app.route('/index', methods=[\"GET\"]) def index(): ranker.index() recommender.index() return 'Indexing done!', 200 @app.route('/ranking', methods=[\"GET\"]) def ranking(): query = request.args.get('query', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = ranker.rank_publications(query, page, rpp) return jsonify(response) @app.route('/recommendation/datasets', methods=[\"GET\"]) def rec_data(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_datasets(item_id, page, rpp) return jsonify(response) @app.route('/recommendation/publications', methods=[\"GET\"]) def rec_pub(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_publications(item_id, page, rpp) return jsonify(response) if __name__ == '__main__': app.run(host='0.0.0.0', port=5000, debug=True) You might have registered some endpoints for building ranking-systems. Since we are only building a recommendation-system, please ignore these endpoints for now.","title":"6. REST-Endpoints with Flask"},{"location":"guides/participants-recommender-publications/#7-indexing-data","text":"Let's start indexing the data from \"livivo_test.jsonl\". This file contains data in jsonlines format, which means, each line is an individual json-object, which represents a single document. Open the file systems.py . This file contains two classes: Ranker and Recommender. As the name says, the first one is for implementing a ranking, the second one for recommender-systems. In this tutorial we will only change the Recommender-Class. At first, we will implement the code for indexing documents. We will read the documents with the help of the jsonlines-package. Don't forget to import the package first. For the sake of simplicity, we will just extract the unique identifier of any document and store them in the python built-in type \"list\". At a later stage, when you work with the full corpus of LIVIVO, which contains more than 60 mio documents, you should switch to a more sophisticated index. You will change the method index(self) so it reads the documents from livivo_testset.jsonl The Ranker-Class in your file systems.py should now look like this: import jsonlines class Recommender(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/livivo/documents/livivo_testset.jsonl') as reader: for obj in reader: self.idx.append(obj['DBRECORDID']) def recommend_datasets(self, item_id, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } def recommend_publications(self, item_id, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) }","title":"7. Indexing data"},{"location":"guides/participants-recommender-publications/#8-recommend-documents-shuffled","text":"Now we will implement our personal algorithm for recommending publications. To keep it simple, our recommender-algorithm picks just a number of random documents. This will give you an idea, how it works and enables you to implement some smart recommender-algorithms after this tutorial. For picking some random entries from our item-list, we can use the choice-method from the random package which is part of the python library and does not need any installation (i.e. you do not need to add it to the requirements.txt file). You will be changing the first line of the method recommend_publications(self, query, page, rpp) to get a randomized item list itemlist = random.choices(self.idx, k=rpp) The Recommender-Cass in your file systems.py should now look like this: import jsonlines import random class Recommender(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/livivo/documents/livivo_testset.jsonl') as reader: for obj in reader: self.idx.append(obj['DBRECORDID']) def recommend_datasets(self, item_id, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } def recommend_publications(self, item_id, page, rpp): itemlist = random.choices(self.idx, k=rpp) return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } If you decide to use external packages, please add them to the file requirements.py . In our example, we decided to use the package jsonlines . Your file requirements.py should now look like this flask jsonlines","title":"8. recommend documents (shuffled)"},{"location":"guides/participants-recommender-publications/#9-setup-virtual-environment","text":"We are now ready to run your application. Before pushing your code to github, you should verify, that everything works as expected. To do so, you should create a virtual-environment, install the necessary dependencies there and run your Ranker on your local machine. Python IDEs (like PyCharm) offer functionalities to create a virtual python environment inside your project. Since we don't know which IDE you are using, we show you, how to create Virtual-Environment manually. Inside the directory of your cloned-repository, please run this command. On Linux and MacOS $ python3 -m venv venv On Windows $ py -m venv venv This creates a virtual python environment in the folder venv . To activate and work with your virtual python environment, please run this commadn: On Linux and MacOs $ source venv/bin/activate On Windows .\\venv\\Scripts\\activate Now, you have to make sure, that all necessary packages are available in your virtual python environment. pip install -r requirements.txt Don't push the folder venv which contains the virtual python environment to your github-repository. It's just for testing your Recommender on your local machine.","title":"9. setup virtual environment"},{"location":"guides/participants-recommender-publications/#10-run-ranker-in-virtual-environment","text":"In your activated virtual environment, start the application. $ python app.py You will get some messages on the shell, indicating, that your Flask-App is running. Now we can do some checks to see if everything works as it should. Please open your browser and access the following address http://0.0.0.0:5000/test (you might need to use http://localhost:5000/test in Windows). Your browser should reply with the message \"Container is running\". This means, Flask is running and serving at Port 5000. Do not worry if your try http://0.0.0.0:5000/ as that entry point is not implemented (i.e. it is expected that you will get an error). Now we want to start indexing documents with our recommender. Please access the following address with your browser http://0.0.0.0:5000/index (or http://localhost:5000/index in Windows). This may take some time, when indexing a big collection. After indexing was successful, your browser should replay with \"Indexing done!\". We are ready to send queries to our ranking-system and get results. Access the following address with your browser http://0.0.0.0:5000/recommendation/publication?item_id=M5339676 (you might need to use http://localhost:5000/ranking?query=test in Windows). Please make sure using an item_id that exists in the indexed dataset, otherwise you'll may not get any results. Your browser will reply with a JSON-Document, that looks like this (itemlist will be different, because the results are randomized): { \"itemlist\": [ \"M7064959\", \"NLM7513803\", \"NLM8300642A\", \"AGRISUS201600020713\", \"AGRISFR2016217161\", \"NLM26061140R\", \"NLM101220129\", \"M28128407\", \"AGRISUS201400054734\", \"NLM101070554\", \"NLM101230052\", \"M17665832\", \"M28313204\", \"NLM9412462\", \"NLM101068566\", \"AGRISJP2009005254\", \"NLM101173006\", \"M4793495\", \"M2965586\", \"M2082902\" ], \"num_found\": 20, \"page\": 0, \"query\": \"test\", \"rpp\": 20 } Congratulations! Your ranker is running! We can now start to build a dockerized version and run unit-tests!","title":"10. run ranker in virtual environment"},{"location":"guides/participants-recommender-publications/#11-build-docker-container-and-run-unit-tests","text":"You are now ready to build your ranker as a docker-container and run unit-tests to check if everything is working as expected, before pushing your code back to github. Navigate to the folder test . Make sure, you still have your virtual environment activated and stopped your ranking application. First, install the python-dependencies needed for running the unit-tests: $ pip install -r requirements.txt Next, we are ready to build and run your ranker as docker-container. Please run the python-script \"docker_build_run.py\". $ python docker_build_run.py Open your browser and please verifiy, if the endpoints are accessible: - http://0.0.0.0:5000/test (http://localhost:5000/test in Windows) - http://0.0.0.0:5000/index (http://localhost:5000/index in Windows) - http://0.0.0.0:5000/recommendation/publications?item_id=M8498126 (http://localhost:5000/recommendation/publications?item_id=M8498126 in Windows) Now we can run the unit-tests: $ python test_recommendation_publications.py This will run 6 different tests, which your container has to pass, before it can be integrated into STELLA The Script should print the message \"OK\". If you are using Windows, make sure you target 'localhost' rather than '0.0.0.0' on the IP variable in the test (i.e. IP = 'localhost' for Windows; for other OS IP = '0.0.0.0. should work).","title":"11. Build docker-container and run unit-tests"},{"location":"guides/participants-recommender-publications/#12-push-your-changes-to-github","text":"Now you are ready to push your ranker back to github. Add the changed files to the the staging area. git add systems.py requirements.txt Save the changes to you local repository. git commit -m \"add systems and requirements\" Update remote branch with local commit. git push origin main Your recommender-system is now ready for integration into the STELLA-infrastructure. Please make sure, that the visibility of your repository is set to \"public\".","title":"12. push your changes to github"},{"location":"guides/participants-recommender/","text":"How to integrate a recommendation micro-service Steps to implement a dockerize application for participating in Living Lab for evaluating your REC systems in a live environment of gesis search which is a search engine for finding information about social science research data and open access publications. Table of Contents 0. [Prerequisites](#10) 1. [Data](#0) 2. [Implementing Ranking Algorithm](#1) 3. [Implementing Dockerize Flask App](#2) 4. [Next Steps](#3) <hr> 0. Prerequisites Before starting this tutorial, make sure all requirements in the README.md are fulfilled. 1.Data A corpus od publication 93k and Research data 83k metadata from GESIS Leibniz Institute for the Social Sciences Metadata in different languages (mixed and separated) !cd data && mkdir gesis-search && mkdir gesis-search/datasets && mkdir gesis-search/documents !wget -O gesis-search/datasets/dataset.jsonl \\ https://th-koeln.sciebo.de/s/OBm0NLEwz1RYl9N/download?path=%2Fgesis-search%2Fdatasets&files=dataset.jsonl -Q --show-progress !wget -O gesis-search/publications.jsonl \\ https://th-koeln.sciebo.de/s/OBm0NLEwz1RYl9N/download?path=%2Fgesis-search%2Fdocuments&files=publication.jsonl -Q --show-progress !chown -R 775 data/* PATH = \"./data/gesis-search/\" import json import jsonlines import pandas as pd import numpy as np import pickle import random pd.set_option(\"display.max_columns\", None) with jsonlines.open(PATH+\"publications/publication.jsonl\") as f : pub = [obj for obj in f] with jsonlines.open(PATH+\"datasets/dataset.jsonl\") as f2 : dataset = [obj for obj in f2] pubdf = pd.DataFrame(pub) pubdf = pubdf.set_index('id') datasetdf = pd.DataFrame(dataset) datasetdf = datasetdf.set_index('id') print(\"Number of publication: \",len(pubdf)) print(\"Metadata are: \" ,list(pubdf.columns)) pubdf.head(3) Number of publication: 93953 Metadata are: ['title', 'abstract', 'topic', 'person', 'links', 'subtype', 'document_type', 'coreAuthor', 'doi', 'date'] title abstract topic person links subtype document_type coreAuthor doi date id gesis-ssoar-1002 New Concerns, More Cooperation? How Non-Tradit... None [Indien, Wirtschaftsbeziehungen, bilaterale Be... [Biba, Sebastian] [{'label': 'Link', 'link': 'https://journals.s... journal_article Zeitschriftenaufsatz [Biba, Sebastian] None 2016 gesis-ssoar-1006 Buddhism in Current China-India Diplomacy Buddhism is being emphasised strongly in both ... [China, Indien, bilaterale Beziehungen, Au\u00dfenp... [Scott, David] [{'label': 'Link', 'link': 'https://journals.s... journal_article Zeitschriftenaufsatz [Scott, David] None 2016 gesis-ssoar-10066 Zukunftsaufgaben der Humanisierung des Arbeits... Das seit 1974 vom BMFT gef\u00f6rderte Programm \"Fr... [Arbeitswelt, Technik, Rationalisierung, Arbei... [Altmann, Norbert, D\u00fcll, Klaus, Lutz, Burkart] [{'label': 'Link', 'link': 'http://www.ssoar.i... book Buch [Altmann, Norbert, D\u00fcll, Klaus, Lutz, Burkart] None 1987 print(\"Number of Research Data: \",len(datasetdf)) print(\"Metadata are: \" ,list(datasetdf.columns)) datasetdf.head(3) Number of Research Data: 83225 Metadata are: ['title', 'subtype', 'abstract', 'person', 'time_collection', 'countries_collection', 'methodology_collection', 'universe', 'selection_method', 'doi', 'publication_year', 'topic'] title subtype abstract person time_collection countries_collection methodology_collection universe selection_method doi publication_year topic id ZA0018 Einstellung zur Wehrbereitschaft und Demokrati... dbk Vergleichsstudie bei der Zivilbev\u00f6lkerung zu e... None 10.1960 - 11.1960 [Deutschland] M\u00fcndliche Befragung mit standardisiertem Frage... Alter: 16 Jahre und \u00e4lter. Mehrstufige Zufallsauswahl \\r\\n doi:10.4232/1.11581 2013 [Konflikte, Sicherheit und Frieden, Politische... ZA0025 Einstellung zur Monarchie (Niederlande)\\r\\n dbk Einstellung der Niederl\u00e4nder zu den Deutschen ... None 06.1965 - 07.1965 [Niederlande] M\u00fcndliche Befragung mit standardisiertem Frage... Alter: 20 Jahre und \u00e4lter Quotenauswahl doi:10.4232/1.0025 1965 [Politische Verhaltensweisen und Einstellungen... ZA0042 Politische Einstellungen (Juni 1966)\\r\\n dbk Beurteilung der Parteien.<br/><br/>Themen: Beu... None 06.1966 - 07.1966 [Deutschland] M\u00fcndliche Befragung mit standardisiertem Frage... Alter: 16-79 Jahre Mehrstufige Zufallsauswahl \\r\\n doi:10.4232/1.0042 1966 [Politische Verhaltensweisen und Einstellungen... 2. Implementing the Recommendation Algorithm In the following we implement a simple app to create randomize recommendation for every publication. You will find out how simple it is. idx = [] with jsonlines.open('./data/gesis-search/datasets/dataset.jsonl') as reader: for obj in reader: idx.append(obj.get('id')) def recommend_datasets(item_id, page, rpp): itemlist = random.choices(idx, k=rpp) return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } recommend_datasets(\"gesis-ssoar-1002\", 1, 5) { \"page\": 1, \"rpp\": 5, \"item_id\": \"gesis-ssoar-1002\", \"itemlist\": [\"datasearch-httpseasy-dans-knaw-nloai--oaieasy-dans-knaw-nleasy-dataset32489\", \"datasearch-httpseasy-dans-knaw-nloai--oaieasy-dans-knaw-nleasy-dataset76673\", \"ZA5859\", \"ZA8682\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de4527\"], \"num_found\": 5} 3.Implementing Dockerize Flask App Application structure API Endpoints Endpoints To connect your system with STELLA, your container has to provide endpoints according to our interface. Most importantly, your system has to implement an indexing-endpoint. This endpoint is called when your system is used for the first time. It builds a search-index from the data provided by the site. The recommendations endpoints must return an ordered list of document-ids in JSON format. If you provide these endpoints, your results will be integrated seamlessly into the sites\u2019 pages. GET /test : print the name o container GET /index : index the data for retrieval GET /recommendation/datasets?<string:item_id> : Retrieve a ranking corresponding to the query specified at the endpoint. A JSON object with maximally 10 entries will be returned. app.py you don't need to change this file from flask import Flask, request, jsonify from systems import Ranker, Recommender app = Flask(__name__) ranker = Ranker() recommender = Recommender() @app.route('/test', methods=[\"GET\"]) def test(): return 'Container is running', 200 @app.route('/index', methods=[\"GET\"]) def index(): ranker.index() recommender.index() return 'Indexing done!', 200 @app.route('/ranking', methods=[\"GET\"]) def ranking(): query = request.args.get('query', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = ranker.rank_publications(query, page, rpp) return jsonify(response) @app.route('/recommendation/datasets', methods=[\"GET\"]) def rec_data(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_datasets(item_id, page, rpp) return jsonify(response) @app.route('/recommendation/publications', methods=[\"GET\"]) def rec_pub(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_publications(item_id, page, rpp) return jsonify(response) if __name__ == '__main__': app.run(host='0.0.0.0', port=5000, debug=True) system.py import jsonlines import random class Ranker(object): def __init__(self): self.idx = None def index(self): pass def rank_publications(self, query, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'query': query, 'itemlist': itemlist, 'num_found': len(itemlist) } class Recommender(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/gesis-search/datasets/dataset.jsonl') as reader: for obj in reader: self.idx.append(obj.get('id')) def recommend_datasets(self, item_id, page, rpp): # implement your ranking algorithm here! itemlist = random.choices(self.idx, k=rpp) return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } def recommend_publications(self, item_id, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } DockerFile FROM python:3.7 COPY requirements.txt requirements.txt RUN python -m pip install -r requirements.txt COPY . . ENTRYPOINT python3 app.py Running the App $ cd gesis_rec_micro $ docker build -t participant/random-rec . $ docker run -p 5000:5000 participant/random-rec Test the app http://0.0.0.0:5000/index (ignore errors if any) http://0.0.0.0:5000/recommendation/datasets?item_id=gesis-ssoar-44449 { \"item_id\": \"gesis-ssoar-44449\", \"itemlist\": [ \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de542142\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de462150\", \"datasearch-httpseasy-dans-knaw-nloai--oaieasy-dans-knaw-nleasy-dataset51047\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de438799\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de585980\", \"datasearch-httpsoai-datacite-orgoai--oaioai-datacite-org57070\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de438015\", \"datasearch-httpsoai-datacite-orgoai--oaioai-datacite-org15413441\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de519570\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de7788\", \"datasearch-httpsdataverse-unc-eduoai--hdl1902-29H-792102\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de549431\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de449775\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de450194\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de656781\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de434948\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de433497\", \"ZA7177\", \"ZA8333\", \"datasearch-httpseasy-dans-knaw-nloai--oaieasy-dans-knaw-nleasy-dataset35905\" ], \"num_found\": 20, \"page\": 0, \"rpp\": 20 }","title":"Tutorial: Recommendation micro-service"},{"location":"guides/participants-recommender/#how-to-integrate-a-recommendation-micro-service","text":"Steps to implement a dockerize application for participating in Living Lab for evaluating your REC systems in a live environment of gesis search which is a search engine for finding information about social science research data and open access publications.","title":"How to integrate a recommendation micro-service"},{"location":"guides/participants-recommender/#table-of-contents","text":"0. [Prerequisites](#10) 1. [Data](#0) 2. [Implementing Ranking Algorithm](#1) 3. [Implementing Dockerize Flask App](#2) 4. [Next Steps](#3) <hr>","title":"Table of Contents"},{"location":"guides/participants-recommender/#0-prerequisites","text":"Before starting this tutorial, make sure all requirements in the README.md are fulfilled.","title":"0. Prerequisites "},{"location":"guides/participants-recommender/#1data","text":"A corpus od publication 93k and Research data 83k metadata from GESIS Leibniz Institute for the Social Sciences Metadata in different languages (mixed and separated) !cd data && mkdir gesis-search && mkdir gesis-search/datasets && mkdir gesis-search/documents !wget -O gesis-search/datasets/dataset.jsonl \\ https://th-koeln.sciebo.de/s/OBm0NLEwz1RYl9N/download?path=%2Fgesis-search%2Fdatasets&files=dataset.jsonl -Q --show-progress !wget -O gesis-search/publications.jsonl \\ https://th-koeln.sciebo.de/s/OBm0NLEwz1RYl9N/download?path=%2Fgesis-search%2Fdocuments&files=publication.jsonl -Q --show-progress !chown -R 775 data/* PATH = \"./data/gesis-search/\" import json import jsonlines import pandas as pd import numpy as np import pickle import random pd.set_option(\"display.max_columns\", None) with jsonlines.open(PATH+\"publications/publication.jsonl\") as f : pub = [obj for obj in f] with jsonlines.open(PATH+\"datasets/dataset.jsonl\") as f2 : dataset = [obj for obj in f2] pubdf = pd.DataFrame(pub) pubdf = pubdf.set_index('id') datasetdf = pd.DataFrame(dataset) datasetdf = datasetdf.set_index('id') print(\"Number of publication: \",len(pubdf)) print(\"Metadata are: \" ,list(pubdf.columns)) pubdf.head(3) Number of publication: 93953 Metadata are: ['title', 'abstract', 'topic', 'person', 'links', 'subtype', 'document_type', 'coreAuthor', 'doi', 'date'] title abstract topic person links subtype document_type coreAuthor doi date id gesis-ssoar-1002 New Concerns, More Cooperation? How Non-Tradit... None [Indien, Wirtschaftsbeziehungen, bilaterale Be... [Biba, Sebastian] [{'label': 'Link', 'link': 'https://journals.s... journal_article Zeitschriftenaufsatz [Biba, Sebastian] None 2016 gesis-ssoar-1006 Buddhism in Current China-India Diplomacy Buddhism is being emphasised strongly in both ... [China, Indien, bilaterale Beziehungen, Au\u00dfenp... [Scott, David] [{'label': 'Link', 'link': 'https://journals.s... journal_article Zeitschriftenaufsatz [Scott, David] None 2016 gesis-ssoar-10066 Zukunftsaufgaben der Humanisierung des Arbeits... Das seit 1974 vom BMFT gef\u00f6rderte Programm \"Fr... [Arbeitswelt, Technik, Rationalisierung, Arbei... [Altmann, Norbert, D\u00fcll, Klaus, Lutz, Burkart] [{'label': 'Link', 'link': 'http://www.ssoar.i... book Buch [Altmann, Norbert, D\u00fcll, Klaus, Lutz, Burkart] None 1987 print(\"Number of Research Data: \",len(datasetdf)) print(\"Metadata are: \" ,list(datasetdf.columns)) datasetdf.head(3) Number of Research Data: 83225 Metadata are: ['title', 'subtype', 'abstract', 'person', 'time_collection', 'countries_collection', 'methodology_collection', 'universe', 'selection_method', 'doi', 'publication_year', 'topic'] title subtype abstract person time_collection countries_collection methodology_collection universe selection_method doi publication_year topic id ZA0018 Einstellung zur Wehrbereitschaft und Demokrati... dbk Vergleichsstudie bei der Zivilbev\u00f6lkerung zu e... None 10.1960 - 11.1960 [Deutschland] M\u00fcndliche Befragung mit standardisiertem Frage... Alter: 16 Jahre und \u00e4lter. Mehrstufige Zufallsauswahl \\r\\n doi:10.4232/1.11581 2013 [Konflikte, Sicherheit und Frieden, Politische... ZA0025 Einstellung zur Monarchie (Niederlande)\\r\\n dbk Einstellung der Niederl\u00e4nder zu den Deutschen ... None 06.1965 - 07.1965 [Niederlande] M\u00fcndliche Befragung mit standardisiertem Frage... Alter: 20 Jahre und \u00e4lter Quotenauswahl doi:10.4232/1.0025 1965 [Politische Verhaltensweisen und Einstellungen... ZA0042 Politische Einstellungen (Juni 1966)\\r\\n dbk Beurteilung der Parteien.<br/><br/>Themen: Beu... None 06.1966 - 07.1966 [Deutschland] M\u00fcndliche Befragung mit standardisiertem Frage... Alter: 16-79 Jahre Mehrstufige Zufallsauswahl \\r\\n doi:10.4232/1.0042 1966 [Politische Verhaltensweisen und Einstellungen...","title":"1.Data "},{"location":"guides/participants-recommender/#2-implementing-the-recommendation-algorithm","text":"In the following we implement a simple app to create randomize recommendation for every publication. You will find out how simple it is. idx = [] with jsonlines.open('./data/gesis-search/datasets/dataset.jsonl') as reader: for obj in reader: idx.append(obj.get('id')) def recommend_datasets(item_id, page, rpp): itemlist = random.choices(idx, k=rpp) return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } recommend_datasets(\"gesis-ssoar-1002\", 1, 5) { \"page\": 1, \"rpp\": 5, \"item_id\": \"gesis-ssoar-1002\", \"itemlist\": [\"datasearch-httpseasy-dans-knaw-nloai--oaieasy-dans-knaw-nleasy-dataset32489\", \"datasearch-httpseasy-dans-knaw-nloai--oaieasy-dans-knaw-nleasy-dataset76673\", \"ZA5859\", \"ZA8682\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de4527\"], \"num_found\": 5}","title":"2. Implementing the Recommendation Algorithm "},{"location":"guides/participants-recommender/#3implementing-dockerize-flask-app","text":"","title":"3.Implementing Dockerize Flask App "},{"location":"guides/participants-recommender/#application-structure","text":"","title":"Application structure"},{"location":"guides/participants-recommender/#api-endpoints","text":"","title":"API Endpoints"},{"location":"guides/participants-recommender/#endpoints","text":"To connect your system with STELLA, your container has to provide endpoints according to our interface. Most importantly, your system has to implement an indexing-endpoint. This endpoint is called when your system is used for the first time. It builds a search-index from the data provided by the site. The recommendations endpoints must return an ordered list of document-ids in JSON format. If you provide these endpoints, your results will be integrated seamlessly into the sites\u2019 pages. GET /test : print the name o container GET /index : index the data for retrieval GET /recommendation/datasets?<string:item_id> : Retrieve a ranking corresponding to the query specified at the endpoint. A JSON object with maximally 10 entries will be returned.","title":"Endpoints"},{"location":"guides/participants-recommender/#apppy","text":"you don't need to change this file from flask import Flask, request, jsonify from systems import Ranker, Recommender app = Flask(__name__) ranker = Ranker() recommender = Recommender() @app.route('/test', methods=[\"GET\"]) def test(): return 'Container is running', 200 @app.route('/index', methods=[\"GET\"]) def index(): ranker.index() recommender.index() return 'Indexing done!', 200 @app.route('/ranking', methods=[\"GET\"]) def ranking(): query = request.args.get('query', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = ranker.rank_publications(query, page, rpp) return jsonify(response) @app.route('/recommendation/datasets', methods=[\"GET\"]) def rec_data(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_datasets(item_id, page, rpp) return jsonify(response) @app.route('/recommendation/publications', methods=[\"GET\"]) def rec_pub(): item_id = request.args.get('item_id', None) page = request.args.get('page', default=0, type=int) rpp = request.args.get('rpp', default=20, type=int) response = recommender.recommend_publications(item_id, page, rpp) return jsonify(response) if __name__ == '__main__': app.run(host='0.0.0.0', port=5000, debug=True)","title":"app.py"},{"location":"guides/participants-recommender/#systempy","text":"import jsonlines import random class Ranker(object): def __init__(self): self.idx = None def index(self): pass def rank_publications(self, query, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'query': query, 'itemlist': itemlist, 'num_found': len(itemlist) } class Recommender(object): def __init__(self): self.idx = None def index(self): self.idx = [] with jsonlines.open('./data/gesis-search/datasets/dataset.jsonl') as reader: for obj in reader: self.idx.append(obj.get('id')) def recommend_datasets(self, item_id, page, rpp): # implement your ranking algorithm here! itemlist = random.choices(self.idx, k=rpp) return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) } def recommend_publications(self, item_id, page, rpp): itemlist = [] return { 'page': page, 'rpp': rpp, 'item_id': item_id, 'itemlist': itemlist, 'num_found': len(itemlist) }","title":"system.py"},{"location":"guides/participants-recommender/#dockerfile","text":"FROM python:3.7 COPY requirements.txt requirements.txt RUN python -m pip install -r requirements.txt COPY . . ENTRYPOINT python3 app.py","title":"DockerFile"},{"location":"guides/participants-recommender/#running-the-app","text":"$ cd gesis_rec_micro $ docker build -t participant/random-rec . $ docker run -p 5000:5000 participant/random-rec","title":"Running the App"},{"location":"guides/participants-recommender/#test-the-app","text":"http://0.0.0.0:5000/index (ignore errors if any) http://0.0.0.0:5000/recommendation/datasets?item_id=gesis-ssoar-44449 { \"item_id\": \"gesis-ssoar-44449\", \"itemlist\": [ \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de542142\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de462150\", \"datasearch-httpseasy-dans-knaw-nloai--oaieasy-dans-knaw-nleasy-dataset51047\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de438799\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de585980\", \"datasearch-httpsoai-datacite-orgoai--oaioai-datacite-org57070\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de438015\", \"datasearch-httpsoai-datacite-orgoai--oaioai-datacite-org15413441\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de519570\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de7788\", \"datasearch-httpsdataverse-unc-eduoai--hdl1902-29H-792102\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de549431\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de449775\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de450194\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de656781\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de434948\", \"datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de433497\", \"ZA7177\", \"ZA8333\", \"datasearch-httpseasy-dans-knaw-nloai--oaieasy-dans-knaw-nleasy-dataset35905\" ], \"num_found\": 20, \"page\": 0, \"rpp\": 20 }","title":"Test the app"},{"location":"guides/participants-resources/","text":"YouTube - LiLAS@CLEF21: Implementing a recommendation service GitHub - Micro template","title":"Resources"},{"location":"guides/pyterrier/","text":"Multi-container application based on Pyterrier This guide provides setup instructions for a simple instance of the stella-app with micro-services based on Pyterrier . The resulting multi-container application contains several Pyterrier-based micro-services with different ranking methods, and additionally, the dashboard service of the stella-server . Prerequisites Python>=3.6 Docker docker-compose Setup 1. Download the data and prepare the index Pyterrier has a good support of the data catalog ir_datasets . In this guide, we will use ir_datasets to prepare index files before starting the stella-app . First, install the Python package: pip install --upgrade ir_datasets We make use of the Cord19 dataset (more specifically, the metadata) that was also used as part of TREC Covid . Execute the following code cell to write the index files into the specified subfolder: import pyterrier as pt pt.init() dataset = pt.get_dataset('irds:cord19') # Index cord19 indexer = pt.IterDictIndexer('./indices/cord19') index_ref = indexer.index(dataset.get_corpus_iter(), fields=['title', 'doi', 'date', 'abstract']) 2. Clone stella-app and copy the index files Next, clone the repository of the stella-app from Github: git clone https://github.com/stella-project/stella-app.git And afterward, move the index files into the index directory of the stella-app . All micro-services will share this index. mv ./indices/cord19 stella-app/index/ 3. Start stella-app In order to run the multi-container application, make sure you have Docker and docker-compose installed. docker-compose -f stella-app/yml/pyterrier.yml up -d It will take some time to build the application. You can verify if every container is running via the CLI commands or with an administration interface like Portainer . 4. Send a request to the stella-app Below you will find an example request of how to retrieve a ranking for the query coronavirus origin : curl localhost:8080/stella/api/v1/ranking?query=coronavirus%20origin&rpp=10 In response, you receive a JSON-formatted output like the following: { \"body\": { \"1\": { \"docid\": \"pl48ev5o\", \"type\": \"EXP\" }, \"2\": { \"docid\": \"75773gwg\", \"type\": \"BASE\" }, \"3\": { \"docid\": \"kn2z7lho\", \"type\": \"BASE\" }, \"4\": { \"docid\": \"xwi9pdd2\", \"type\": \"EXP\" }, \"5\": { \"docid\": \"irkjiqll\", \"type\": \"EXP\" }, \"6\": { \"docid\": \"4fb291hq\", \"type\": \"BASE\" }, \"7\": { \"docid\": \"kqqantwg\", \"type\": \"BASE\" }, \"8\": { \"docid\": \"jpnbppry\", \"type\": \"EXP\" }, \"9\": { \"docid\": \"es7q6c90\", \"type\": \"EXP\" }, \"10\": { \"docid\": \"ne5r4d4b\", \"type\": \"BASE\" } }, \"header\": { \"container\": { \"base\": \"pyterrier_bm25\", \"exp\": \"pyterrier_pl2\" }, \"hits\": 10, \"page\": 0, \"q\": \"coronavirus origin\", \"rid\": 3, \"rpp\": 10, \"sid\": \"30fae19ec7574ad68af0bff23409adb5\" } }","title":"Multi-container application based on Pyterrier"},{"location":"guides/pyterrier/#multi-container-application-based-on-pyterrier","text":"This guide provides setup instructions for a simple instance of the stella-app with micro-services based on Pyterrier . The resulting multi-container application contains several Pyterrier-based micro-services with different ranking methods, and additionally, the dashboard service of the stella-server .","title":"Multi-container application based on Pyterrier"},{"location":"guides/pyterrier/#prerequisites","text":"Python>=3.6 Docker docker-compose","title":"Prerequisites"},{"location":"guides/pyterrier/#setup","text":"","title":"Setup"},{"location":"guides/pyterrier/#1-download-the-data-and-prepare-the-index","text":"Pyterrier has a good support of the data catalog ir_datasets . In this guide, we will use ir_datasets to prepare index files before starting the stella-app . First, install the Python package: pip install --upgrade ir_datasets We make use of the Cord19 dataset (more specifically, the metadata) that was also used as part of TREC Covid . Execute the following code cell to write the index files into the specified subfolder: import pyterrier as pt pt.init() dataset = pt.get_dataset('irds:cord19') # Index cord19 indexer = pt.IterDictIndexer('./indices/cord19') index_ref = indexer.index(dataset.get_corpus_iter(), fields=['title', 'doi', 'date', 'abstract'])","title":"1. Download the data and prepare the index"},{"location":"guides/pyterrier/#2-clone-stella-app-and-copy-the-index-files","text":"Next, clone the repository of the stella-app from Github: git clone https://github.com/stella-project/stella-app.git And afterward, move the index files into the index directory of the stella-app . All micro-services will share this index. mv ./indices/cord19 stella-app/index/","title":"2. Clone stella-app and copy the index files"},{"location":"guides/pyterrier/#3-start-stella-app","text":"In order to run the multi-container application, make sure you have Docker and docker-compose installed. docker-compose -f stella-app/yml/pyterrier.yml up -d It will take some time to build the application. You can verify if every container is running via the CLI commands or with an administration interface like Portainer .","title":"3. Start stella-app"},{"location":"guides/pyterrier/#4-send-a-request-to-the-stella-app","text":"Below you will find an example request of how to retrieve a ranking for the query coronavirus origin : curl localhost:8080/stella/api/v1/ranking?query=coronavirus%20origin&rpp=10 In response, you receive a JSON-formatted output like the following: { \"body\": { \"1\": { \"docid\": \"pl48ev5o\", \"type\": \"EXP\" }, \"2\": { \"docid\": \"75773gwg\", \"type\": \"BASE\" }, \"3\": { \"docid\": \"kn2z7lho\", \"type\": \"BASE\" }, \"4\": { \"docid\": \"xwi9pdd2\", \"type\": \"EXP\" }, \"5\": { \"docid\": \"irkjiqll\", \"type\": \"EXP\" }, \"6\": { \"docid\": \"4fb291hq\", \"type\": \"BASE\" }, \"7\": { \"docid\": \"kqqantwg\", \"type\": \"BASE\" }, \"8\": { \"docid\": \"jpnbppry\", \"type\": \"EXP\" }, \"9\": { \"docid\": \"es7q6c90\", \"type\": \"EXP\" }, \"10\": { \"docid\": \"ne5r4d4b\", \"type\": \"BASE\" } }, \"header\": { \"container\": { \"base\": \"pyterrier_bm25\", \"exp\": \"pyterrier_pl2\" }, \"hits\": 10, \"page\": 0, \"q\": \"coronavirus origin\", \"rid\": 3, \"rpp\": 10, \"sid\": \"30fae19ec7574ad68af0bff23409adb5\" } }","title":"4. Send a request to the stella-app"},{"location":"guides/single-machine/","text":"Setup guide (single server instance) 0. Overview This guide is intended for setting up an instance of the stella-app and the stella-server on a single machine. Both applications have to be in the same Docker network. Only then, the stella-app 's HTTP requests can reach the REST-API of the stella-server . These instructions will guide you through the following steps: Clone the repositories ( stella-server , stella-app ) Download the datasets (extracting and placing them in the correct directory) Configure the stella-server and the stella-app Build both Docker applications Sanity checks By the end, you should have both applications running and can simulate interactions with the stella-app, which in turn sends the feedback to the stella-server. By logging into the stella-server, you should be able to see plots in the dashboard and JSON-formatted downloads of the feedback data should be possible. Prerequisites: :warning: Make sure docker , docker-compose and the docker-sdk [1] are installed and executable! :warning: [1] The docker-sdk is actually only required for developing micro-services with experimental systems. Start with fresh copies of the repositories and make sure previous builds of the Docker images are removed. It may not be enough to stop the containers. In some cases, previous image builds (which are not up-to-date) might be re-used. 1. Clone the repositories Clone the repository of the stella-server: git clone https://github.com/stella-project/stella-server Clone the repository of the stella-app: git clone https://github.com/stella-project/stella-app 2. Download the datasets Download the datasets that are provided by LIVIVO and GESIS from the publicly shared Sciebo folder . More specifically, you should download the two folders gesis-search/ and livivo/ and place the uncompressed folders in the data/ directory of the stella-app. 3. Configure the stella-server and the stella-app Both applications have a config.py file. Leaving the configurations untouched after the repositories have been cloned is fine - there is actually no need to change anything here. Those who want to directly dive in, can skip the following lines and can continue with the Docker builds. For the curious minds, there are seperate pages for the stella-server 's config.py and the stella-app 's config.py . There you will find detailed descriptions of each configuration. For now, it is interesting to have a look at the following fields of stella-app 's config.py . Check if conf['app']['DEBUG'] = False . Check if conf['app']['BULK_INDEX'] = True . When starting the stella-app all experimental will start to index the data in parallel. There is no need to trigger any indexing process \"manually\". Check if conf[\"app\"][\"STELLA_SERVER_API\"] = \"http://nginx/stella/api/v1\" . This is the address of the stella-server in the Docker network. Only if both applications are in the same Docker network, they can communicate. Check the credentials that are used by the stella-app : conf[\"app\"][\"STELLA_SERVER_USER\"] = \"gesis@stella.org\" conf[\"app\"][\"STELLA_SERVER_PASS\"] = \"pass\" conf[\"app\"][\"STELLA_SERVER_USERNAME\"] = \"GESIS\" Per default, GESIS is set as the user of the stella-app , but you can change them to LIVIVO's with the help of the credentials given below. 4. Build both Docker applications The stella-server has to be built first! Its default network will be used as our Docker network. Build the stella-server with: cd stella-server/ docker-compose up -d Afterwards, the stella-app can be built. In the repository you will find two .yml -files. As part of this guide, you have to use the docker-compose.yml file . It will add the stella-app to the Docker network of the stella-server . You can ignore the local.yml - this one is intended for a setup independent of the stella-server . Build the stella-app with: cd stella-app/ docker-compose up -d This is the right moment to get a cup of coffee or any other beverage of your choice. It takes a while to build all the Docker images (all dependencies have to be retrieved from the web) and once the images are running in containers, the indexing will take some time. Please note that at the current stage, the stella-app has already too many experimental systems, so not all systems can start the indexing in parallel when starting the app on my laptop (16GB RAM, i7 4Cores@1.9GHz). Even though the stella-app forces all systems to build the index at once, some experimental systems will probably remain without an index, after the app has been started on lower-end devices. A current workaround for this problem is to trigger the indexing for specific experimental systems that do not have an index. This can either be done by the corresponding REST-endpoint ( /stella/api/v1/index/<string:container_name> ) or by visiting the dashboard of the stella-app and using the index button. 5. Sanity checks Once everything has been set up. We can check a few things first. 1st sanity check: visiting the dashboard If you did not change anything in the configurations, the stella-server should be visitable at http://0.0.0.0:80 . Log in with one of the provided credentials below. You should able to see a list with pre-registered system at http://0.0.0.0:80/systems and can visit an \"empty\" dashboard at http://0.0.0.0:80/dashboard . In the following, we will fill up the database of the stella-server with some feedback data. 2nd sanity check: Simulating feedback data and posting it via the REST endpoints of the stella-server In this step, we will simulate interactions and use the REST endpoints that are actually used by the stella-app later on. It can be seen as a pre-assessment, if the stella-server behaves as intended. Use the simulate.py script and make sure, the address of the stella-server is set correctly in the script. Once executed, you can revisit the dashboard and should be provided with some visualizations. Likewise, JSON-formatted feedback data should be exportable from the systems' overview. 3rd sanity check: Simulating feedback data and posting it via the REST endpoints of the stella-app In the previous step, we were using the REST endpoints that are intended to be used by the stella-app . In this step, we will also simulate data and send it to the stella-app , which in turn, will send it to the stella-server . Use the simulate.py script in the repository of the stella-app (make sure the address of the stella-app is correct). Revisit the stella-server and have a look at the dashboard. Pre-registered users of the stella-server Participants username email password participant_a participant_a@stella.org pass participant_b participant_b@stella.org pass Sites username email password GESIS gesis@stella.org pass LIVIVO livivo@stella.org pass Administrators username email password stella-admin admin@stella.org pass","title":"Setup guide"},{"location":"guides/single-machine/#setup-guide-single-server-instance","text":"","title":"Setup guide (single server instance)"},{"location":"guides/single-machine/#0-overview","text":"This guide is intended for setting up an instance of the stella-app and the stella-server on a single machine. Both applications have to be in the same Docker network. Only then, the stella-app 's HTTP requests can reach the REST-API of the stella-server . These instructions will guide you through the following steps: Clone the repositories ( stella-server , stella-app ) Download the datasets (extracting and placing them in the correct directory) Configure the stella-server and the stella-app Build both Docker applications Sanity checks By the end, you should have both applications running and can simulate interactions with the stella-app, which in turn sends the feedback to the stella-server. By logging into the stella-server, you should be able to see plots in the dashboard and JSON-formatted downloads of the feedback data should be possible.","title":"0. Overview"},{"location":"guides/single-machine/#prerequisites","text":":warning: Make sure docker , docker-compose and the docker-sdk [1] are installed and executable! :warning: [1] The docker-sdk is actually only required for developing micro-services with experimental systems. Start with fresh copies of the repositories and make sure previous builds of the Docker images are removed. It may not be enough to stop the containers. In some cases, previous image builds (which are not up-to-date) might be re-used.","title":"Prerequisites:"},{"location":"guides/single-machine/#1-clone-the-repositories","text":"Clone the repository of the stella-server: git clone https://github.com/stella-project/stella-server Clone the repository of the stella-app: git clone https://github.com/stella-project/stella-app","title":"1. Clone the repositories"},{"location":"guides/single-machine/#2-download-the-datasets","text":"Download the datasets that are provided by LIVIVO and GESIS from the publicly shared Sciebo folder . More specifically, you should download the two folders gesis-search/ and livivo/ and place the uncompressed folders in the data/ directory of the stella-app.","title":"2. Download the datasets"},{"location":"guides/single-machine/#3-configure-the-stella-server-and-the-stella-app","text":"Both applications have a config.py file. Leaving the configurations untouched after the repositories have been cloned is fine - there is actually no need to change anything here. Those who want to directly dive in, can skip the following lines and can continue with the Docker builds. For the curious minds, there are seperate pages for the stella-server 's config.py and the stella-app 's config.py . There you will find detailed descriptions of each configuration. For now, it is interesting to have a look at the following fields of stella-app 's config.py . Check if conf['app']['DEBUG'] = False . Check if conf['app']['BULK_INDEX'] = True . When starting the stella-app all experimental will start to index the data in parallel. There is no need to trigger any indexing process \"manually\". Check if conf[\"app\"][\"STELLA_SERVER_API\"] = \"http://nginx/stella/api/v1\" . This is the address of the stella-server in the Docker network. Only if both applications are in the same Docker network, they can communicate. Check the credentials that are used by the stella-app : conf[\"app\"][\"STELLA_SERVER_USER\"] = \"gesis@stella.org\" conf[\"app\"][\"STELLA_SERVER_PASS\"] = \"pass\" conf[\"app\"][\"STELLA_SERVER_USERNAME\"] = \"GESIS\" Per default, GESIS is set as the user of the stella-app , but you can change them to LIVIVO's with the help of the credentials given below.","title":"3. Configure the stella-server and the stella-app"},{"location":"guides/single-machine/#4-build-both-docker-applications","text":"The stella-server has to be built first! Its default network will be used as our Docker network. Build the stella-server with: cd stella-server/ docker-compose up -d Afterwards, the stella-app can be built. In the repository you will find two .yml -files. As part of this guide, you have to use the docker-compose.yml file . It will add the stella-app to the Docker network of the stella-server . You can ignore the local.yml - this one is intended for a setup independent of the stella-server . Build the stella-app with: cd stella-app/ docker-compose up -d This is the right moment to get a cup of coffee or any other beverage of your choice. It takes a while to build all the Docker images (all dependencies have to be retrieved from the web) and once the images are running in containers, the indexing will take some time. Please note that at the current stage, the stella-app has already too many experimental systems, so not all systems can start the indexing in parallel when starting the app on my laptop (16GB RAM, i7 4Cores@1.9GHz). Even though the stella-app forces all systems to build the index at once, some experimental systems will probably remain without an index, after the app has been started on lower-end devices. A current workaround for this problem is to trigger the indexing for specific experimental systems that do not have an index. This can either be done by the corresponding REST-endpoint ( /stella/api/v1/index/<string:container_name> ) or by visiting the dashboard of the stella-app and using the index button.","title":"4. Build both Docker applications"},{"location":"guides/single-machine/#5-sanity-checks","text":"Once everything has been set up. We can check a few things first.","title":"5. Sanity checks"},{"location":"guides/single-machine/#1st-sanity-check-visiting-the-dashboard","text":"If you did not change anything in the configurations, the stella-server should be visitable at http://0.0.0.0:80 . Log in with one of the provided credentials below. You should able to see a list with pre-registered system at http://0.0.0.0:80/systems and can visit an \"empty\" dashboard at http://0.0.0.0:80/dashboard . In the following, we will fill up the database of the stella-server with some feedback data.","title":"1st sanity check: visiting the dashboard"},{"location":"guides/single-machine/#2nd-sanity-check-simulating-feedback-data-and-posting-it-via-the-rest-endpoints-of-the-stella-server","text":"In this step, we will simulate interactions and use the REST endpoints that are actually used by the stella-app later on. It can be seen as a pre-assessment, if the stella-server behaves as intended. Use the simulate.py script and make sure, the address of the stella-server is set correctly in the script. Once executed, you can revisit the dashboard and should be provided with some visualizations. Likewise, JSON-formatted feedback data should be exportable from the systems' overview.","title":"2nd sanity check: Simulating feedback data and posting it via the REST endpoints of the stella-server"},{"location":"guides/single-machine/#3rd-sanity-check-simulating-feedback-data-and-posting-it-via-the-rest-endpoints-of-the-stella-app","text":"In the previous step, we were using the REST endpoints that are intended to be used by the stella-app . In this step, we will also simulate data and send it to the stella-app , which in turn, will send it to the stella-server . Use the simulate.py script in the repository of the stella-app (make sure the address of the stella-app is correct). Revisit the stella-server and have a look at the dashboard.","title":"3rd sanity check: Simulating feedback data and posting it via the REST endpoints of the stella-app"},{"location":"guides/single-machine/#pre-registered-users-of-the-stella-server","text":"","title":"Pre-registered users of the stella-server"},{"location":"guides/single-machine/#participants","text":"username email password participant_a participant_a@stella.org pass participant_b participant_b@stella.org pass","title":"Participants"},{"location":"guides/single-machine/#sites","text":"username email password GESIS gesis@stella.org pass LIVIVO livivo@stella.org pass","title":"Sites"},{"location":"guides/single-machine/#administrators","text":"username email password stella-admin admin@stella.org pass","title":"Administrators"}]}